{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.7.0'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "import boto3\n",
    "from boto3.dynamodb.conditions import Key\n",
    "import os\n",
    "from google_images_download import google_images_download\n",
    "import glob\n",
    "import PIL\n",
    "import json\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pickle\n",
    "\n",
    "import textacy\n",
    "import en_core_web_sm\n",
    "\n",
    "# from custo import greedy_algorithm\n",
    "import input_data_preprocessing.corpus_stats as c_stats\n",
    "\n",
    "textacy.spacier.doc_extensions.set_doc_extensions()\n",
    "#import code\n",
    "textacy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Text Data for inputTerm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputTerm = 'photosynthesis'\n",
    "topic ='biology'\n",
    "\n",
    "\n",
    "tblName = \"ResourceDocuments\"\n",
    "nodeIdentifierName = \"photosynthesis-photosynthesis-photosynthesis-biology\"\n",
    "\n",
    "termTxtToImage_flpth = 'data/photosynthesis'\n",
    "text_flpth = os.path.join(termTxtToImage_flpth, 'text')\n",
    "img_flpth =  os.path.join(termTxtToImage_flpth, 'images')\n",
    "imageLog_fir='logs'\n",
    "\n",
    "resourceDbName = 'dynamodb'\n",
    "#s3Bucket = \"egm-bucket/TEXT_TO_IMAGE_DATA/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data from Resource Db: \n",
    "photosynthesis whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NUmber of Items in ResourceDb: 14'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Definitions for photosynthesis from dynamodb\n",
    "\n",
    "## Connect to dynamodb\n",
    "dynamodbClient = boto3.resource(\"dynamodb\")\n",
    "# client = boto3.client('dynamodb')\n",
    "# display(client.describe_table(TableName=tblName))\n",
    "\n",
    "## Connect to table with resources\n",
    "resourceTbl = dynamodbClient.Table(tblName)\n",
    "# display(resourceTbl.global_secondary_indexes)\n",
    "display(\"NUmber of Items in ResourceDb: {}\".format(resourceTbl.item_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load text into pandas \n",
    "- For data munging\n",
    "    - stats\n",
    "    - Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Db Response Shape: (14, 13)\n",
      "Db Response Shape: (7, 13)\n",
      "Index(['IMAGES', 'NODE_IDENTIFIER', 'POS', 'RESOURCE', 'RESOURCE_ATTRIBUTION',\n",
      "       'RESOURCE_DATATYPE', 'RESOURCE_SOURCE', 'RESOURCE_TYPE', 'RESOURCE_URL',\n",
      "       'TERM', 'TIME_DOWNLOADED', 'TOPIC', 'UNIQUE_IDENTIFIER'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "response = resourceTbl.query(\n",
    "    IndexName='NODE_IDENTIFIER-index',\n",
    "    KeyConditionExpression=Key('NODE_IDENTIFIER').eq(nodeIdentifierName)\n",
    ")\n",
    "\n",
    "# Pass through pandas for some data munging\n",
    "rsrc_df = pd.DataFrame(response[\"Items\"])\n",
    "print(\"Db Response Shape: {}\".format(rsrc_df.shape))\n",
    "\n",
    "rsrc_df.drop_duplicates(['RESOURCE'], keep='last', inplace=True)\n",
    "rsrc_df.reset_index(drop=True)\n",
    "\n",
    "print(\"Db Response Shape: {}\".format(rsrc_df.shape))\n",
    "print(rsrc_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4        century\n",
       "5        wordnet\n",
       "9     wiktionary\n",
       "10     wikipedia\n",
       "11         gcide\n",
       "12     wikipedia\n",
       "13    ahd-legacy\n",
       "Name: RESOURCE_SOURCE, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsrc_df[\"RESOURCE_SOURCE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest corpus data from df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_corpus(df):\n",
    "    # Load into textacy to delimit sentences\n",
    "    img_labels = rsrc_df.to_dict(orient=\"records\")\n",
    "    records = textacy.io.split_records(img_labels, 'RESOURCE',itemwise=True)\n",
    "\n",
    "    # Load english model\n",
    "    en = en_core_web_sm.load()\n",
    "    corpus = textacy.Corpus(lang=en, data=records)\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Corpus(7 docs, 963 tokens)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captionsCorpus = df_to_corpus(rsrc_df)\n",
    "captionsCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc(37 tokens: \"A chemical combination brought about by the act...\")\n",
      "Doc(14 tokens: \"synthesis of compounds with the aid of radiant ...\")\n",
      "Doc(24 tokens: \"The process by which plants and other photoauto...\")\n",
      "Doc(512 tokens: \"Photosynthesis is a process used by plants and ...\")\n",
      "Doc(200 tokens: \"The process of constructive metabolism by which...\")\n",
      "Doc(140 tokens: \"Photosynthesis is a process used by plants and ...\")\n",
      "Doc(36 tokens: \"The process in green plants and certain other o...\")\n"
     ]
    }
   ],
   "source": [
    "for doc in captionsCorpus:\n",
    "    print(doc._.preview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Corpus image text into multiple captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Finished calculating CorpusStats\n",
      "INFO:root:Shortest Doc - Number of tokens 14\n",
      "DEBUG:root:Finished - Maximizimizing number of captions per image\n",
      "INFO:root:MaximizeDocCaptions - Number of captions 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Corpus: Corpus(7 docs, 963 tokens)\n"
     ]
    }
   ],
   "source": [
    "import input_data_preprocessing.corpus_stats as c_stats\n",
    "import input_data_preprocessing.utils as idp_utils\n",
    "import input_data_preprocessing.captions as idp_captions\n",
    "\n",
    "# Input - A Spacy corpus of texts corresponding to a set of images\n",
    "print(f\"Input Corpus: {captionsCorpus}\")\n",
    "\n",
    "# 1  Calculate corpus stats\n",
    "corpusStats = c_stats.CorpusStats(captionsCorpus)\n",
    "\n",
    "# 2  Extract the shortest doc from a corpus\n",
    "shortestDoc = idp_utils.find_shortest_doc(captionsCorpus, corpusStats.min_tokens)\n",
    "\n",
    "# 3  Maximize the shortest doc captions and return a list of captions greater than entered\n",
    "shortestDocCaptions = idp_captions.MaximizeDocCaptions(shortestDoc )\n",
    "\n",
    "# 4  Segment all the texts in the corpus to equal the number of captions in the shortest doc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['synthesis of compounds',\n",
       " 'aid of radiant',\n",
       " 'especially in plants',\n",
       " 'compounds with the aid',\n",
       " 'aid of radiant energy']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortestDocCaptions.caption_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Finished - Maximizimizing number of captions per image\n",
      "INFO:root:MaximizeDocCaptions - Number of captions 14\n",
      "DEBUG:root:Finished - Maximizimizing number of captions per image\n",
      "INFO:root:MaximizeDocCaptions - Number of captions 5\n",
      "DEBUG:root:Finished - Maximizimizing number of captions per image\n",
      "INFO:root:MaximizeDocCaptions - Number of captions 12\n",
      "DEBUG:root:Ideal caption length: 483\n",
      "DEBUG:root:Ideal caption length: 193\n",
      "DEBUG:root:Finished - Maximizimizing number of captions per image\n",
      "INFO:root:MaximizeDocCaptions - Number of captions 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Resizing Image Caption 0\n",
      "\n",
      " Resizing Image Caption 1\n",
      "\n",
      " Resizing Image Caption 2\n",
      "\n",
      " Resizing Image Caption 3\n",
      "Number of characters per captions: 554\n",
      "Number of characters per captions: 412\n",
      "Number of characters per captions: 302\n",
      "Number of characters per captions: 320\n",
      "Number of characters per captions: 412\n",
      "\n",
      " Resizing Image Caption 4\n",
      "Number of characters per captions: 202\n",
      "Number of characters per captions: 142\n",
      "Number of characters per captions: 208\n",
      "Number of characters per captions: 137\n",
      "Number of characters per captions: 163\n",
      "\n",
      " Resizing Image Caption 5\n",
      "\n",
      " Resizing Image Caption 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # 2 Check if we can expand the captions for text less than 2 sents long\n",
    "# if corpusStats.min_sents <= 2: # TODO add check for all the captions.\n",
    "     \n",
    "max_captions = shortestDocCaptions.num_of_captions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "corpus_captions_lst = list()\n",
    "to_shortDocs_lst = list()\n",
    "# d. Loop over corpus and re-size labels to the max captions i.e ideally split by sentences\n",
    "for docidx, doc in enumerate(captionsCorpus):\n",
    "    print(f\"\\n Resizing Image Caption {docidx}\")\n",
    "    image_captions_lst = list()\n",
    "    # Check if the doc the labaels need to be minimized or expanded\n",
    "    if doc._.n_sents==max_captions:\n",
    "        \n",
    "        # Split sents into captions and noramlize text i.e lowercase everything.\n",
    "        image_captions_lst = [idp_captions.normalize_caption_text(sent.text) for sent in doc.sents]\n",
    "    \n",
    "    elif doc._.n_sents<max_captions:\n",
    "        \n",
    "        # Maximize the captions per image\n",
    "        maxedCaptions = idp_captions.MaximizeDocCaptions(doc)\n",
    "#         captions_df  =  idp_utils.captionsLst_to_df(maxedCaptions.caption_lst)\n",
    "        \n",
    "#         # Minimize if maxed captions \n",
    "#         docCaptions = idp_captions.MinimizeDocCaptions(captions_df, max_captions)\n",
    "        image_captions_lst = docCaptions.captions_lst\n",
    "    elif doc._.n_sents>max_captions:\n",
    "        \n",
    "        # Split sentences into list  before munging\n",
    "        captions_lst = [sent.text for sent in doc.sents]        \n",
    "        \n",
    "        \n",
    "        docCaptions = idp_captions.MinimizeDocCaptions(sents_df, max_captions)\n",
    "        image_captions_lst = docCaptions.captions_lst\n",
    "            \n",
    "    corpus_captions_lst.append(image_captions_lst)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the process of constructive metabolism by which carbohydrates are formed from water vapor and the carbon dioxide of the air in the chlorophyll containing tissues of plants exposed to the action of light',\n",
       " 'it was formerly called assimilation but this is now commonly used as in animal physiology the details of the process are not yet clearly known',\n",
       " 'baeyer s theory is that the carbon dioxide is reduced to carbon monoxide which uniting with the hydrogen of the water in the cell produces formaldehyde the latter forming various sugars through polymerization',\n",
       " 'vines suggests that the carbohydrates are secretion products of the chloroplasts derived from decomposition of previously formed proteids',\n",
       " 'the food substances are usually quickly translocated those that accumulate being changed to starch which appears in the cells almost simultaneously with the sugars']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docCaptions.captions_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[A chemical combination brought about by the action of light, as in the formation of carbohydrates in living plants from the carbon di-oxid and water of the air under the influence of sunlight.,\n",
       " synthesis of compounds with the aid of radiant energy (especially in plants),\n",
       " The process by which plants and other photoautotrophs generate carbohydrates and oxygen from carbon dioxide, water, and light energy in chloroplasts.,\n",
       " The process in green plants and certain other organisms by which carbohydrates are synthesized from carbon dioxide and water using light as an energy source. Most forms of photosynthesis release oxygen as a byproduct.]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_shortDocs_lst\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_captions(doc,  min_objective='shape'):\n",
    "    \n",
    "    if min_objective=='shape':\n",
    "        pass\n",
    "    elif min_objective=='similarity':\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in doc.sents:\n",
    "    print(type(sent.text))\n",
    "    x = textacy.preprocess.preprocess_text(str(sent.text), fix_unicode=True, lowercase=False, \n",
    "                                       no_urls=False, no_emails=False, \n",
    "                                       no_phone_numbers=False, no_numbers=False, \n",
    "                                       no_currency_symbols=False, no_punct=False, \n",
    "                                       no_contractions=False, \n",
    "                                       no_accents=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textacy.preprocess.preprocess_text(captions_lst[0], fix_unicode=True, lowercase=False, \n",
    "                                       no_urls=False, no_emails=False, \n",
    "                                       no_phone_numbers=False, no_numbers=False, \n",
    "                                       no_currency_symbols=False, no_punct=False, \n",
    "                                       no_contractions=False, \n",
    "                                       no_accents=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(captions_lst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(doc._.n_sents for doc in captionsCorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "shortestDocs = captionsCorpus.get(lambda x: len(x)==minToken_num)\n",
    "shortestDoc = list(shortestDocs)[0]\n",
    "\n",
    "# 2  Get a list of captions parsed from the doc with the min amount of tokens\n",
    "captions_lst = maximize_captions(shortestDoc)\n",
    "max_captions = len(captions_lst)\n",
    "\n",
    "# 3 Go through the rest of the documents in the corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = textacy.constants.POS_REGEX_PATTERNS[\"en\"][\"PP\"]\n",
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(textacy.extract.pos_regex_matches(shortestDoc, p1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = '<NOUN> <ADP> <NOUN> ' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(textacy.extract.pos_regex_matches(shortestDoc, p1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortestDoc._.to_tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captionsCorpus[1]._.to_bag_of_terms(ngrams=(4), \n",
    "                              entities=True, \n",
    "                              weighting=\"binary\",\n",
    "                             as_strings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(shortestDoc._.to_terms_list(ngrams=(3,4), \n",
    "                                 normalize = 'lower',\n",
    "                                 entities=True, \n",
    "                              weighting=\"binary\",\n",
    "                                 filter_punct = True,\n",
    "                                 drop_determiners = True,\n",
    "                             as_strings=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(shortestDoc._.to_terms_list(ngrams=(4), \n",
    "                                 normalize = 'lower',\n",
    "                                 entities=True, \n",
    "                              weighting=\"binary\",\n",
    "                                 filter_punct = True,\n",
    "                                 drop_determiners = True,\n",
    "                             as_strings=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "textacy.spacier.doc_extensions.get_doc_extensions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortestDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(textacy.extract.words(shortestDoc, \n",
    "                            filter_stops=False, \n",
    "                            filter_punct=True, \n",
    "                            filter_nums=False,\n",
    "                            min_freq=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(textacy.extract.noun_chunks(shortestDoc, drop_determiners=False, min_freq=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Make captions for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortestDoc._.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(textacy.extract.noun_chunks(shortestDoc, drop_determiners=False, min_freq=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Labels for text to image model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_directories(directory_flpth):\n",
    "    # Handle missing Directory\n",
    "    if not os.path.exists(directory_flpth):\n",
    "        \n",
    "        os.makedirs(directory_flpth)\n",
    "        print(\"Made new directory: {}\".format(directory_flpth))\n",
    "        # print(os.path.join(dirname, flpth))\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return\n",
    "\n",
    "# Create text file for each doc - Each Doc maps to an image\n",
    "\n",
    "## TODO: incoroporate number of labals per line\n",
    "def labels_to_imageTxt_files(rsrc_df, trainingData_term, trainigData_flpth='../data'):\n",
    "    \n",
    "    # Handle if a data directory for a term exists e.g. data/photosynthesis\n",
    "    dirname = os.path.abspath('')\n",
    "    termData_flpth = os.path.join(dirname, trainigData_flpth)\n",
    "    handle_missing_directories(termData_flpth)\n",
    "    \n",
    "    \n",
    "    ### Move resource df to textacy\n",
    "   \n",
    "    # Load into textacy to delimit sentences\n",
    "    img_labels = rsrc_df.to_dict(orient=\"records\")\n",
    "    text_stream, metadata_stream = textacy.io.split_records(img_labels, 'RESOURCE')\n",
    "\n",
    "    # Load english model\n",
    "    en = en_core_web_sm.load()\n",
    "    labels_corpus = textacy.Corpus(lang=en, texts=text_stream, metadatas=metadata_stream)\n",
    "    \n",
    "    caption_filename_path = os.path.join(trainigData_flpth, \"captions.pickle\")\n",
    "    \n",
    "    # Loop through corpus and write document to flpth (s3)\n",
    "    ''' Each doc in a corpus equals and image'''\n",
    "    for ix, doc in enumerate(labels_corpus):\n",
    "        print(\"Number of Sentences: {}\".format(doc.n_sents))\n",
    "        \n",
    "        # Paths to directories (Where to write the text files)\n",
    "        filename = \"{}_{}.txt\".format(trainingData_term, ix)\n",
    "        path_to_file = \"{}/{}\".format(trainigData_flpth, filename)\n",
    "        \n",
    "        # Write captions for google images\n",
    "        f =  open(path_to_file, 'w')\n",
    "        \n",
    "        # Parse Document into sentences\n",
    "        for sent in doc.sents:\n",
    "            caption = textacy.preprocess.preprocess_text(sent.text,\n",
    "                                               lowercase=True,\n",
    "                                               no_punct=True\n",
    "                                              )\n",
    "            # f.write(label+\"\\n\" )\n",
    "            f.write(caption+\" \" )\n",
    "            \n",
    "        f.close()\n",
    "        \n",
    "    return ix + 1 # Count using 1 as start\n",
    "\n",
    "# process labels for images\n",
    "\n",
    "\n",
    "trainingData_term = 'photosynthesis'\n",
    "txt_trainingData_flpth='{}/text'.format(termTxtToImage_flpth, 'text')\n",
    "\n",
    "numText_files = labels_to_imageTxt_files(rsrc_df, trainingData_term, txt_trainingData_flpth)\n",
    "numText_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Images from google "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_images(term ,img_args):\n",
    "    \n",
    "    # Download Images \n",
    "    response = google_images_download.googleimagesdownload()\n",
    "    img_paths = response.download(img_args)\n",
    "    \n",
    "    # Post Process google image results\n",
    "    for idx, f in enumerate(img_paths[term]):\n",
    "        \n",
    "        # Open Google image resulst and conver to jpeg\n",
    "        img = PIL.Image.open(f)\n",
    "        img_filetype = img.format.lower()  # 'JPEG'\n",
    "        \n",
    "        rgb_img = img.convert('RGB')\n",
    "        img.close()\n",
    "        \n",
    "        # Make new filenme to allign with text file name\n",
    "        filename = \"{}_{}.{}\".format(trainingData_term, idx, 'jpg')\n",
    "        newfilepath_f = os.path.join(os.path.dirname(f), filename)\n",
    "        \n",
    "        # Save and image\n",
    "        rgb_img.save(newfilepath_f)\n",
    "        os.remove(f)\n",
    "    \n",
    "    \n",
    "    return response \n",
    "\n",
    "img_args = {\"keywords\":\"sun\",\n",
    "             \"format\": \"png\",\n",
    "              \"limit\": 20,\n",
    "             \"output_directory\": 'data',\n",
    "            \"metadata\": True,\n",
    "            \"image_directory\": \"photosynthesis/images\",\n",
    "            \"no_download\": False,\n",
    "            \"extract_metadata\":True\n",
    "            # \"size\":\"icon\"\n",
    "           }\n",
    "\n",
    "response = download_images(trainingData_term, img_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tigDataLoader.utiils as dataloader\n",
    "import os\n",
    "import json\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictTerm = \"photosynthesis\"\n",
    "dataTerm = \"photosynthesis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base file io inputs\n",
    "trainData_flpth = os.path.join('data', predictTerm)\n",
    "text_flpth = os.path.join(trainData_flpth, 'text')\n",
    "img_flpth =  os.path.join(trainData_flpth, 'images')\n",
    "\n",
    "# Google imagae download metadata\n",
    "imageLog_fir='logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformText_to_captions(txtDoc, numCaptions_per_image=5, txtSplit_method='svo'):\n",
    "    # Take textacy doc and converts to a list of captions for an image\n",
    "    \n",
    "    if txtSplit_method=='noun_chunks':\n",
    "        split_list = list(textacy.extract.noun_chunks(txtDoc, drop_determiners=False, min_freq=1))\n",
    "    if txtSplit_method=='svo':\n",
    "        split_list = list(textacy.extract.subject_verb_object_triples(txtDoc))\n",
    "    \n",
    "    return split_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Download images\n",
    "- from google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_args = {\"keywords\": dataTerm,\n",
    "             \"format\": \"png\",\n",
    "              \"limit\": 100,\n",
    "             \"output_directory\": 'data',\n",
    "            \"metadata\": True,\n",
    "            \"image_directory\": \"{}/images/\".format(predictTerm),\n",
    "            \"no_download\": False,\n",
    "            \"extract_metadata\":True,\n",
    "            \"type\": \"clipart\"\n",
    "           }\n",
    "img_paths, response = dataloader.download_images(dataTerm, img_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download text from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load text into textacy\n",
    "imgTxt_corpus = df_to_corpus()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(labels_corpus.docs[0].sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get(\"https://ssec.si.edu/stemvisions-blog/what-photosynthesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Fake data\n",
    "import shutil\n",
    "import itertools\n",
    "\n",
    "# Get a list of the original files f\n",
    "txtDirFileNm_lst = glob.glob(text_flpth+\"/**/*.txt\", recursive=True)\n",
    "imgDirFileNm_lst = glob.glob(img_flpth+\"/**/*.jpg\", recursive=True)\n",
    "\n",
    "fileCombo_lst = list(itertools.product(txtDirFileNm_lst,imgDirFileNm_lst))\n",
    "\n",
    "# for item in fileCombo_lst:\n",
    "    \n",
    "#     # Get text name\n",
    "#     txtget_relfilename\n",
    "\n",
    "# # # Create list paired tuple pairs\n",
    "# # comboFlpth_lst = list(zip(txtDirFileNm_lst, imgDirFileNm_lst))\n",
    "# # comboFlpth_lst\n",
    "\n",
    "# # new_list = []\n",
    "# # for k,v in comboFlpth_lst.iteritems():\n",
    "# #     new_list.extend([x for x in combinations(v, 2)]) \n",
    "# # # for txtFile, imgFile in comboFlpth_dict:\n",
    "# # #     # Make copies of files and rename\n",
    "# # #     shutil.copyfile(txtFile, dst)\n",
    "# # #     shutil.copyfile(imgFile, dst)\n",
    "\n",
    "# # new_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df = pd.read_csv(\"RUNS.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"s_loss\", y=\"embedding_dim\", data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_algorithm(captions_df['n_chars'].tolist(), ideal_caption_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_algorithm(captions_df['n_chars'].tolist(), ideal_caption_length)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'synthesis of compounds with the aid of radiant energy (especially in plants)'\n",
    "\n",
    "synthesis=noun\n",
    "of = preposition\n",
    "compound = phrase of prepostion (noun)\n",
    "with = preposition\n",
    "the = difinite article\n",
    "aid = noun\n",
    "of = preposition\n",
    "radiant = adj epithet (the adjective that describes the noun)\n",
    "energy = noun\n",
    "with the aid of radiant energy is the phrase of the preposition\n",
    "especcially = asverb\n",
    "in = preposition\n",
    "plamts is a noun+\n",
    "\n",
    "[[('synthesis', 'NOUN'),\n",
    "  ('of', 'ADP'),\n",
    "  ('compounds', 'NOUN'),\n",
    "  ('with', 'ADP'),\n",
    "  ('the', 'DET'),\n",
    "  ('aid', 'NOUN'),\n",
    "  ('of', 'ADP'),\n",
    "  ('radiant', 'ADJ'),\n",
    "  ('energy', 'NOUN'),\n",
    "  ('(', 'PUNCT'),\n",
    "  ('especially', 'ADV'),\n",
    "  ('in', 'ADP'),\n",
    "  ('plants', 'NOUN'),\n",
    "  (')', 'PUNCT')]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load text from s3 to df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "inputTerm_lst = ['photosynthesis', 'sun', 'water']\n",
    "\n",
    "inputTerm_df_lst = []\n",
    "for inputTerm in inputTerm_lst:\n",
    "    nodeIdentifierName = \"{}-{}-{}-{}\".format(inputTerm, inputTerm, inputTerm, topic)\n",
    "    s3key = \"NODE-DATASTORE-TMP/{}/normedFedSearch.json\".format(nodeIdentifierName)\n",
    "    s3 = boto3.client('s3')\n",
    "    result = s3.get_object(Bucket='egm-bucket', Key=s3key)\n",
    "    file_content = result['Body'].read().decode('utf-8')\n",
    "    json_content = json.loads(file_content)\n",
    "    df = pd.DataFrame(json_content)\n",
    "    inputTerm_df_lst.append(df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "captions_df = pd.concat(inputTerm_df_lst)\n",
    "captions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36-ml",
   "language": "python",
   "name": "py36-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
