{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.7.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "import boto3\n",
    "from boto3.dynamodb.conditions import Key\n",
    "import os\n",
    "from google_images_download import google_images_download\n",
    "import glob\n",
    "import PIL\n",
    "import json\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pickle\n",
    "\n",
    "import textacy\n",
    "import en_core_web_sm\n",
    "\n",
    "# from custo import greedy_algorithm\n",
    "#import input_data_preprocessing.corpus_stats as c_stats\n",
    "\n",
    "textacy.spacier.doc_extensions.set_doc_extensions()\n",
    "#import code\n",
    "textacy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/environment/AttnGAN/data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/environment/AttnGAN/data/photosynthesis'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir_name = 'data'\n",
    "\n",
    "metadata_folder_name = 'photosynthesis'\n",
    "txt_dir_flname =  \"text\"\n",
    "img_dir_flname =  'images'\n",
    "\n",
    "\n",
    "data_dir_flpth = os.path.abspath(data_dir_name)\n",
    "print(data_dir_flpth)\n",
    "metadata_flpth = os.path.join(data_dir_flpth, metadata_folder_name)\n",
    "\n",
    "text_training_data_flpth = os.path.join(metadata_flpth, txt_dir_flname)\n",
    "image_training_data_flpth = os.path.join(metadata_flpth, img_dir_flname)\n",
    "text_training_data_flpth\n",
    "data_dir_name\n",
    "metadata_flpth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ec2-user/environment/AttnGAN/data/photosynthesis/text/captions.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1b02eb200e57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Check pickles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcaptions_pik_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_training_data_flpth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'captions.pickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmetadata_captions_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptions_pik_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmetadata_captions_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ec2-user/environment/AttnGAN/data/photosynthesis/text/captions.pickle'"
     ]
    }
   ],
   "source": [
    "## Check pickles\n",
    "captions_pik_path = os.path.join(text_training_data_flpth, 'captions.pickle')\n",
    "metadata_captions_p = pickle.load( open(captions_pik_path, \"rb\" ) )\n",
    "metadata_captions_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Text Data for inputTerm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputTerm = 'photosynthesis'\n",
    "topic ='biology'\n",
    "\n",
    "\n",
    "tblName = \"ResourceDocuments\"\n",
    "nodeIdentifierName = \"photosynthesis-photosynthesis-photosynthesis-biology\"\n",
    "\n",
    "termTxtToImage_flpth = 'data/photosynthesis'\n",
    "text_flpth = os.path.join(termTxtToImage_flpth, 'text')\n",
    "img_flpth =  os.path.join(termTxtToImage_flpth, 'images')\n",
    "imageLog_fir='logs'\n",
    "\n",
    "resourceDbName = 'dynamodb'\n",
    "#s3Bucket = \"egm-bucket/TEXT_TO_IMAGE_DATA/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data from Resource Db: \n",
    "photosynthesis whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NUmber of Items in ResourceDb: 14'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Definitions for photosynthesis from dynamodb\n",
    "\n",
    "## Connect to dynamodb\n",
    "dynamodbClient = boto3.resource(\"dynamodb\")\n",
    "# client = boto3.client('dynamodb')\n",
    "# display(client.describe_table(TableName=tblName))\n",
    "\n",
    "## Connect to table with resources\n",
    "resourceTbl = dynamodbClient.Table(tblName)\n",
    "# display(resourceTbl.global_secondary_indexes)\n",
    "display(\"NUmber of Items in ResourceDb: {}\".format(resourceTbl.item_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load text into pandas \n",
    "- For data munging\n",
    "    - stats\n",
    "    - Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Db Response Shape: (14, 13)\n",
      "Db Response Shape: (7, 13)\n",
      "Index(['IMAGES', 'NODE_IDENTIFIER', 'POS', 'RESOURCE', 'RESOURCE_ATTRIBUTION',\n",
      "       'RESOURCE_DATATYPE', 'RESOURCE_SOURCE', 'RESOURCE_TYPE', 'RESOURCE_URL',\n",
      "       'TERM', 'TIME_DOWNLOADED', 'TOPIC', 'UNIQUE_IDENTIFIER'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "response = resourceTbl.query(\n",
    "    IndexName='NODE_IDENTIFIER-index',\n",
    "    KeyConditionExpression=Key('NODE_IDENTIFIER').eq(nodeIdentifierName)\n",
    ")\n",
    "\n",
    "# Pass through pandas for some data munging\n",
    "rsrc_df = pd.DataFrame(response[\"Items\"])\n",
    "print(\"Db Response Shape: {}\".format(rsrc_df.shape))\n",
    "\n",
    "rsrc_df.drop_duplicates(['RESOURCE'], keep='last', inplace=True)\n",
    "rsrc_df.reset_index(drop=True)\n",
    "\n",
    "print(\"Db Response Shape: {}\".format(rsrc_df.shape))\n",
    "print(rsrc_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4        century\n",
       "5        wordnet\n",
       "9     wiktionary\n",
       "10     wikipedia\n",
       "11         gcide\n",
       "12     wikipedia\n",
       "13    ahd-legacy\n",
       "Name: RESOURCE_SOURCE, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsrc_df[\"RESOURCE_SOURCE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest corpus data from df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_corpus(df):\n",
    "    # Load into textacy to delimit sentences\n",
    "    img_labels = rsrc_df.to_dict(orient=\"records\")\n",
    "    records = textacy.io.split_records(img_labels, 'RESOURCE',itemwise=True)\n",
    "\n",
    "    # Load english model\n",
    "    en = en_core_web_sm.load()\n",
    "    corpus = textacy.Corpus(lang=en, data=records)\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Corpus(7 docs, 963 tokens)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captionsCorpus = df_to_corpus(rsrc_df)\n",
    "captionsCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc(37 tokens: \"A chemical combination brought about by the act...\")\n",
      "Doc(14 tokens: \"synthesis of compounds with the aid of radiant ...\")\n",
      "Doc(24 tokens: \"The process by which plants and other photoauto...\")\n",
      "Doc(512 tokens: \"Photosynthesis is a process used by plants and ...\")\n",
      "Doc(200 tokens: \"The process of constructive metabolism by which...\")\n",
      "Doc(140 tokens: \"Photosynthesis is a process used by plants and ...\")\n",
      "Doc(36 tokens: \"The process in green plants and certain other o...\")\n"
     ]
    }
   ],
   "source": [
    "for doc in captionsCorpus:\n",
    "    print(doc._.preview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(textacy.extract.noun_chunks(shortestDoc, drop_determiners=False, min_freq=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Make captions for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortestDoc._.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(textacy.extract.noun_chunks(shortestDoc, drop_determiners=False, min_freq=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Labels for text to image model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_directories(directory_flpth):\n",
    "    # Handle missing Directory\n",
    "    if not os.path.exists(directory_flpth):\n",
    "        \n",
    "        os.makedirs(directory_flpth)\n",
    "        print(\"Made new directory: {}\".format(directory_flpth))\n",
    "        # print(os.path.join(dirname, flpth))\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return\n",
    "\n",
    "# Create text file for each doc - Each Doc maps to an image\n",
    "\n",
    "## TODO: incoroporate number of labals per line\n",
    "def labels_to_imageTxt_files(rsrc_df, trainingData_term, trainigData_flpth='../data'):\n",
    "    \n",
    "    # Handle if a data directory for a term exists e.g. data/photosynthesis\n",
    "    dirname = os.path.abspath('')\n",
    "    termData_flpth = os.path.join(dirname, trainigData_flpth)\n",
    "    handle_missing_directories(termData_flpth)\n",
    "    \n",
    "    \n",
    "    ### Move resource df to textacy\n",
    "   \n",
    "    # Load into textacy to delimit sentences\n",
    "    img_labels = rsrc_df.to_dict(orient=\"records\")\n",
    "    text_stream, metadata_stream = textacy.io.split_records(img_labels, 'RESOURCE')\n",
    "\n",
    "    # Load english model\n",
    "    en = en_core_web_sm.load()\n",
    "    labels_corpus = textacy.Corpus(lang=en, texts=text_stream, metadatas=metadata_stream)\n",
    "    \n",
    "    caption_filename_path = os.path.join(trainigData_flpth, \"captions.pickle\")\n",
    "    \n",
    "    # Loop through corpus and write document to flpth (s3)\n",
    "    ''' Each doc in a corpus equals and image'''\n",
    "    for ix, doc in enumerate(labels_corpus):\n",
    "        print(\"Number of Sentences: {}\".format(doc.n_sents))\n",
    "        \n",
    "        # Paths to directories (Where to write the text files)\n",
    "        filename = \"{}_{}.txt\".format(trainingData_term, ix)\n",
    "        path_to_file = \"{}/{}\".format(trainigData_flpth, filename)\n",
    "        \n",
    "        # Write captions for google images\n",
    "        f =  open(path_to_file, 'w')\n",
    "        \n",
    "        # Parse Document into sentences\n",
    "        for sent in doc.sents:\n",
    "            caption = textacy.preprocess.preprocess_text(sent.text,\n",
    "                                               lowercase=True,\n",
    "                                               no_punct=True\n",
    "                                              )\n",
    "            # f.write(label+\"\\n\" )\n",
    "            f.write(caption+\" \" )\n",
    "            \n",
    "        f.close()\n",
    "        \n",
    "    return ix + 1 # Count using 1 as start\n",
    "\n",
    "# process labels for images\n",
    "\n",
    "\n",
    "trainingData_term = 'photosynthesis'\n",
    "txt_trainingData_flpth='{}/text'.format(termTxtToImage_flpth, 'text')\n",
    "\n",
    "numText_files = labels_to_imageTxt_files(rsrc_df, trainingData_term, txt_trainingData_flpth)\n",
    "numText_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Images from google "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_images(term ,img_args):\n",
    "    \n",
    "    # Download Images \n",
    "    response = google_images_download.googleimagesdownload()\n",
    "    img_paths = response.download(img_args)\n",
    "    \n",
    "    # Post Process google image results\n",
    "    for idx, f in enumerate(img_paths[term]):\n",
    "        \n",
    "        # Open Google image resulst and conver to jpeg\n",
    "        img = PIL.Image.open(f)\n",
    "        img_filetype = img.format.lower()  # 'JPEG'\n",
    "        \n",
    "        rgb_img = img.convert('RGB')\n",
    "        img.close()\n",
    "        \n",
    "        # Make new filenme to allign with text file name\n",
    "        filename = \"{}_{}.{}\".format(trainingData_term, idx, 'jpg')\n",
    "        newfilepath_f = os.path.join(os.path.dirname(f), filename)\n",
    "        \n",
    "        # Save and image\n",
    "        rgb_img.save(newfilepath_f)\n",
    "        os.remove(f)\n",
    "    \n",
    "    \n",
    "    return response \n",
    "\n",
    "img_args = {\"keywords\":\"sun\",\n",
    "             \"format\": \"png\",\n",
    "              \"limit\": 20,\n",
    "             \"output_directory\": 'data',\n",
    "            \"metadata\": True,\n",
    "            \"image_directory\": \"photosynthesis/images\",\n",
    "            \"no_download\": False,\n",
    "            \"extract_metadata\":True\n",
    "            # \"size\":\"icon\"\n",
    "           }\n",
    "\n",
    "response = download_images(trainingData_term, img_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tigDataLoader.utiils as dataloader\n",
    "import os\n",
    "import json\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictTerm = \"photosynthesis\"\n",
    "dataTerm = \"photosynthesis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base file io inputs\n",
    "trainData_flpth = os.path.join('data', predictTerm)\n",
    "text_flpth = os.path.join(trainData_flpth, 'text')\n",
    "img_flpth =  os.path.join(trainData_flpth, 'images')\n",
    "\n",
    "# Google imagae download metadata\n",
    "imageLog_fir='logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformText_to_captions(txtDoc, numCaptions_per_image=5, txtSplit_method='svo'):\n",
    "    # Take textacy doc and converts to a list of captions for an image\n",
    "    \n",
    "    if txtSplit_method=='noun_chunks':\n",
    "        split_list = list(textacy.extract.noun_chunks(txtDoc, drop_determiners=False, min_freq=1))\n",
    "    if txtSplit_method=='svo':\n",
    "        split_list = list(textacy.extract.subject_verb_object_triples(txtDoc))\n",
    "    \n",
    "    return split_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Download images\n",
    "- from google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_args = {\"keywords\": dataTerm,\n",
    "             \"format\": \"png\",\n",
    "              \"limit\": 100,\n",
    "             \"output_directory\": 'data',\n",
    "            \"metadata\": True,\n",
    "            \"image_directory\": \"{}/images/\".format(predictTerm),\n",
    "            \"no_download\": False,\n",
    "            \"extract_metadata\":True,\n",
    "            \"type\": \"clipart\"\n",
    "           }\n",
    "img_paths, response = dataloader.download_images(dataTerm, img_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download text from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load text into textacy\n",
    "imgTxt_corpus = df_to_corpus()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(labels_corpus.docs[0].sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get(\"https://ssec.si.edu/stemvisions-blog/what-photosynthesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Fake data\n",
    "import shutil\n",
    "import itertools\n",
    "\n",
    "# Get a list of the original files f\n",
    "txtDirFileNm_lst = glob.glob(text_flpth+\"/**/*.txt\", recursive=True)\n",
    "imgDirFileNm_lst = glob.glob(img_flpth+\"/**/*.jpg\", recursive=True)\n",
    "\n",
    "fileCombo_lst = list(itertools.product(txtDirFileNm_lst,imgDirFileNm_lst))\n",
    "\n",
    "# for item in fileCombo_lst:\n",
    "    \n",
    "#     # Get text name\n",
    "#     txtget_relfilename\n",
    "\n",
    "# # # Create list paired tuple pairs\n",
    "# # comboFlpth_lst = list(zip(txtDirFileNm_lst, imgDirFileNm_lst))\n",
    "# # comboFlpth_lst\n",
    "\n",
    "# # new_list = []\n",
    "# # for k,v in comboFlpth_lst.iteritems():\n",
    "# #     new_list.extend([x for x in combinations(v, 2)]) \n",
    "# # # for txtFile, imgFile in comboFlpth_dict:\n",
    "# # #     # Make copies of files and rename\n",
    "# # #     shutil.copyfile(txtFile, dst)\n",
    "# # #     shutil.copyfile(imgFile, dst)\n",
    "\n",
    "# # new_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df = pd.read_csv(\"RUNS.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"s_loss\", y=\"embedding_dim\", data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_algorithm(captions_df['n_chars'].tolist(), ideal_caption_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_algorithm(captions_df['n_chars'].tolist(), ideal_caption_length)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'synthesis of compounds with the aid of radiant energy (especially in plants)'\n",
    "\n",
    "synthesis=noun\n",
    "of = preposition\n",
    "compound = phrase of prepostion (noun)\n",
    "with = preposition\n",
    "the = difinite article\n",
    "aid = noun\n",
    "of = preposition\n",
    "radiant = adj epithet (the adjective that describes the noun)\n",
    "energy = noun\n",
    "with the aid of radiant energy is the phrase of the preposition\n",
    "especcially = asverb\n",
    "in = preposition\n",
    "plamts is a noun+\n",
    "\n",
    "[[('synthesis', 'NOUN'),\n",
    "  ('of', 'ADP'),\n",
    "  ('compounds', 'NOUN'),\n",
    "  ('with', 'ADP'),\n",
    "  ('the', 'DET'),\n",
    "  ('aid', 'NOUN'),\n",
    "  ('of', 'ADP'),\n",
    "  ('radiant', 'ADJ'),\n",
    "  ('energy', 'NOUN'),\n",
    "  ('(', 'PUNCT'),\n",
    "  ('especially', 'ADV'),\n",
    "  ('in', 'ADP'),\n",
    "  ('plants', 'NOUN'),\n",
    "  (')', 'PUNCT')]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load text from s3 to df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "inputTerm_lst = ['photosynthesis', 'sun', 'water']\n",
    "\n",
    "inputTerm_df_lst = []\n",
    "for inputTerm in inputTerm_lst:\n",
    "    nodeIdentifierName = \"{}-{}-{}-{}\".format(inputTerm, inputTerm, inputTerm, topic)\n",
    "    s3key = \"NODE-DATASTORE-TMP/{}/normedFedSearch.json\".format(nodeIdentifierName)\n",
    "    s3 = boto3.client('s3')\n",
    "    result = s3.get_object(Bucket='egm-bucket', Key=s3key)\n",
    "    file_content = result['Body'].read().decode('utf-8')\n",
    "    json_content = json.loads(file_content)\n",
    "    df = pd.DataFrame(json_content)\n",
    "    inputTerm_df_lst.append(df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "captions_df = pd.concat(inputTerm_df_lst)\n",
    "captions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36-ml",
   "language": "python",
   "name": "py36-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
