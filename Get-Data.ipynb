{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import io\n",
    "import boto3\n",
    "from boto3.dynamodb.conditions import Key\n",
    "import os\n",
    "from google_images_download import google_images_download\n",
    "import glob\n",
    "import PIL\n",
    "import json\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pickle\n",
    "\n",
    "import textacy\n",
    "import en_core_web_sm\n",
    "\n",
    "from IPython.display import SVG\n",
    "\n",
    "from IPython.display import Image\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training data for text to image model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tblName = \"ResourceDocuments\"\n",
    "nodeIdentifierName = \"photosynthesis-photosynthesis-photosynthesis-biology\"\n",
    "\n",
    "termTxtToImage_flpth = 'data/photosynthesis'\n",
    "imageLog_fir='logs'\n",
    "\n",
    "resourceDbName = 'dynamodb'\n",
    "s3Bucket = \"egm-bucket/TEXT_TO_IMAGE_DATA/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data from Resource Db: \n",
    "photosynthesis whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NUmber of Items in ResourceDb: 14'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Definitions for photosynthesis from dynamodb\n",
    "\n",
    "## Connect to dynamodb\n",
    "dynamodbClient = boto3.resource(\"dynamodb\")\n",
    "# client = boto3.client('dynamodb')\n",
    "# display(client.describe_table(TableName=tblName))\n",
    "\n",
    "## Connect to table with resources\n",
    "resourceTbl = dynamodbClient.Table(tblName)\n",
    "# display(resourceTbl.global_secondary_indexes)\n",
    "display(\"NUmber of Items in ResourceDb: {}\".format(resourceTbl.item_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load text into pandas \n",
    "- For data munging\n",
    "    - stats\n",
    "    - Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Db Response Shape: (14, 13)\n",
      "Db Response Shape: (7, 13)\n",
      "Index(['IMAGES', 'NODE_IDENTIFIER', 'POS', 'RESOURCE', 'RESOURCE_ATTRIBUTION',\n",
      "       'RESOURCE_DATATYPE', 'RESOURCE_SOURCE', 'RESOURCE_TYPE', 'RESOURCE_URL',\n",
      "       'TERM', 'TIME_DOWNLOADED', 'TOPIC', 'UNIQUE_IDENTIFIER'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "response = resourceTbl.query(\n",
    "    IndexName='NODE_IDENTIFIER-index',\n",
    "    KeyConditionExpression=Key('NODE_IDENTIFIER').eq(nodeIdentifierName)\n",
    ")\n",
    "\n",
    "# Pass through pandas for some data munging\n",
    "rsrc_df = pd.DataFrame(response[\"Items\"])\n",
    "print(\"Db Response Shape: {}\".format(rsrc_df.shape))\n",
    "\n",
    "rsrc_df.drop_duplicates(['RESOURCE'], keep='last', inplace=True)\n",
    "rsrc_df.reset_index(drop=True)\n",
    "\n",
    "print(\"Db Response Shape: {}\".format(rsrc_df.shape))\n",
    "print(rsrc_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4        century\n",
       "5        wordnet\n",
       "9     wiktionary\n",
       "10     wikipedia\n",
       "11         gcide\n",
       "12     wikipedia\n",
       "13    ahd-legacy\n",
       "Name: RESOURCE_SOURCE, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsrc_df[\"RESOURCE_SOURCE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Labels for text to image model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sentenses: 1\n",
      "Number of Sentenses: 1\n",
      "Number of Sentenses: 1\n",
      "Number of Sentenses: 16\n",
      "Number of Sentenses: 9\n",
      "Number of Sentenses: 5\n",
      "Number of Sentenses: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def handle_missing_directories(directory_flpth):\n",
    "    # Handle missing Directory\n",
    "    if not os.path.exists(directory_flpth):\n",
    "        \n",
    "        os.makedirs(directory_flpth)\n",
    "        print(\"Made new directory: {}\".format(directory_flpth))\n",
    "        # print(os.path.join(dirname, flpth))\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return\n",
    "\n",
    "# Create text file for each doc - Each Doc maps to an image\n",
    "\n",
    "## TODO: incoroporate number of labals per line\n",
    "def labels_to_imageTxt_files(rsrc_df, trainingData_term, trainigData_flpth='../data'):\n",
    "    \n",
    "    # Handle if a data directory for a term exists e.g. data/photosynthesis\n",
    "    dirname = os.path.abspath('')\n",
    "    termData_flpth = os.path.join(dirname, trainigData_flpth)\n",
    "    handle_missing_directories(termData_flpth)\n",
    "    \n",
    "    \n",
    "    ### Move resource df to textacy\n",
    "   \n",
    "    # Load into textacy to delimit sentences\n",
    "    img_labels = rsrc_df.to_dict(orient=\"records\")\n",
    "    text_stream, metadata_stream = textacy.io.split_records(img_labels, 'RESOURCE')\n",
    "\n",
    "    # Load english model\n",
    "    en = en_core_web_sm.load()\n",
    "    labels_corpus = textacy.Corpus(lang=en, texts=text_stream, metadatas=metadata_stream)\n",
    "    \n",
    "    caption_filename_path = os.path.join(trainigData_flpth, \"captions.pickle\")\n",
    "    \n",
    "    # Loop through corpus and write document to flpth (s3)\n",
    "    ''' Each doc in a corpus equals and image'''\n",
    "    for ix, doc in enumerate(labels_corpus):\n",
    "        print(\"Number of Sentenses: {}\".format(doc.n_sents))\n",
    "        \n",
    "        # Paths to directories (Where to write the text files)\n",
    "        filename = \"{}_{}.txt\".format(trainingData_term, ix)\n",
    "        path_to_file = \"{}/{}\".format(trainigData_flpth, filename)\n",
    "        \n",
    "        # Write captions for google images\n",
    "        f =  open(path_to_file, 'w')\n",
    "        \n",
    "        # Parse Document into sentences\n",
    "        for sent in doc.sents:\n",
    "            caption = textacy.preprocess.preprocess_text(sent.text,\n",
    "                                               lowercase=True,\n",
    "                                               no_punct=True\n",
    "                                              )\n",
    "            # f.write(label+\"\\n\" )\n",
    "            f.write(caption+\" \" )\n",
    "            \n",
    "        f.close()\n",
    "        \n",
    "    return ix + 1 # Count using 1 as start\n",
    "\n",
    "# process labels for images\n",
    "\n",
    "\n",
    "trainingData_term = 'photosynthesis'\n",
    "txt_trainingData_flpth='{}/text'.format(termTxtToImage_flpth, 'text')\n",
    "\n",
    "numText_files = labels_to_imageTxt_files(rsrc_df, trainingData_term, txt_trainingData_flpth)\n",
    "numText_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Images from google "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item no.: 1 --> Item name = photosynthesis\n",
      "Evaluating...\n",
      "Starting Download...\n",
      "\n",
      "Image Metadata: {'image_format': 'png', 'image_height': 220, 'image_width': 220, 'image_link': 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/55/Photosynthesis_en.svg/220px-Photosynthesis_en.svg.png', 'image_description': 'Photosynthesis - Wikipedia', 'image_host': 'en.wikipedia.org', 'image_source': 'https://en.wikipedia.org/wiki/Photosynthesis', 'image_thumbnail_url': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS5KkJVlZz81zgJD2edw3thRhA_3dLLlsBtIpyz3qStyfqmoyI6'}\n",
      "Completed Image ====> 1. 220px-photosynthesis_en.svg.png\n",
      "\n",
      "Image Metadata: {'image_format': 'png', 'image_height': 421, 'image_width': 575, 'image_link': 'https://ssec.si.edu/sites/default/files/Photosynthesis_0.png', 'image_description': 'What is Photosynthesis | Smithsonian Science Education Center', 'image_host': 'ssec.si.edu', 'image_source': 'https://ssec.si.edu/stemvisions-blog/what-photosynthesis', 'image_thumbnail_url': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRUztAlqHC8MlNAwnarppl_QGyQ9evf9_f1r3mrOP7kTdJTmYhj'}\n",
      "Completed Image ====> 2. photosynthesis_0.png\n",
      "\n",
      "Image Metadata: {'image_format': 'png', 'image_height': 302, 'image_width': 636, 'image_link': 'https://cdn.kastatic.org/ka-perseus-images/b5696ba86426f4fcc8be09e1a910f0033d241d24.png', 'image_description': 'Intro to photosynthesis (article) | Khan Academy', 'image_host': 'khanacademy.org', 'image_source': 'https://www.khanacademy.org/science/biology/photosynthesis-in-plants/introduction-to-stages-of-photosynthesis/a/intro-to-photosynthesis', 'image_thumbnail_url': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQj2tpqmsSGqMOzOVzz9wj_6TEoXzlBmVqEkHXeY6gxmTIIq9ZzsQ'}\n",
      "Completed Image ====> 3. b5696ba86426f4fcc8be09e1a910f0033d241d24.png\n",
      "\n",
      "Image Metadata: {'image_format': 'png', 'image_height': 369, 'image_width': 480, 'image_link': 'http://www.eschooltoday.com/photosynthesis/images/diagram-of-photosynthesis.png', 'image_description': 'What is photosynthesis?', 'image_host': 'eschooltoday.com', 'image_source': 'http://www.eschooltoday.com/photosynthesis/what-is-photosynthesis.html', 'image_thumbnail_url': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQIOZo3NGhWT5rdtjIx1fTf72QbftWPC9eeCo7QjGrsZTJB2kVc'}\n",
      "Completed Image ====> 4. diagram-of-photosynthesis.png\n",
      "\n",
      "Image Metadata: {'image_format': 'png', 'image_height': 565, 'image_width': 750, 'image_link': 'https://cdn1.byjus.com/wp-content/uploads/2018/11/photosynthesis.png', 'image_description': 'Photosynthesis - Stages, Factors And Importance Of Photosynthesis', 'image_host': 'byjus.com', 'image_source': 'https://byjus.com/biology/photosynthesis/', 'image_thumbnail_url': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTvDDzm35E3hOaqqXrQOJj-vU9qEjOvdnL3IjkKCMQi8qmcXwVuYA'}\n",
      "Completed Image ====> 5. photosynthesis.png\n",
      "\n",
      "Image Metadata: {'image_format': '1', 'image_height': 862, 'image_width': 800, 'image_link': 'https://dr282zn36sxxg.cloudfront.net/datastreams/f-d%3A283a5747964474bdb6059d1e0714ed65e73f3bdf00a2abbb7f9cce72%2BIMAGE_TINY%2BIMAGE_TINY.1', 'image_description': '2. 23: Photosynthesis Summary - Biology LibreTexts', 'image_host': 'bio.libretexts.org', 'image_source': 'https://bio.libretexts.org/Bookshelves/Introductory_and_General_Biology/Book%3A_Introductory_Biology_(CK-12)/2%3A_Cell_Biology/2._23%3A_Photosynthesis_Summary', 'image_thumbnail_url': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRFWPDBJwBPBO5OPDhEa5WR3tX7OkF5MC3zyxMY6bxAobxXaGl1BQ'}\n",
      "Completed Image ====> 6. f-d%3a283a5747964474bdb6059d1e0\n",
      "\n",
      "Image Metadata: {'image_format': 'png', 'image_height': 767, 'image_width': 836, 'image_link': 'http://science4fun.info/wp-content/uploads/2016/01/photosynthesis.png', 'image_description': 'Photosynthesis - (Infomation + Facts) - Science4Fun', 'image_host': 'science4fun.info', 'image_source': 'http://science4fun.info/photosynthesis/', 'image_thumbnail_url': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTyz1OblHJ2A1qXnZHrd8O2MaXpCasgXpZz3CqMLvHrwiS-D28S'}\n",
      "Completed Image ====> 7. photosynthesis.png\n",
      "\n",
      "Errors: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def download_images(term ,img_args):\n",
    "    \n",
    "    # Download Images \n",
    "    response = google_images_download.googleimagesdownload()\n",
    "    img_paths = response.download(img_args)\n",
    "    \n",
    "    # Post Process google image results\n",
    "    for idx, f in enumerate(img_paths[term]):\n",
    "        \n",
    "        # Open Google image resulst and conver to jpeg\n",
    "        img = PIL.Image.open(f)\n",
    "        img_filetype = img.format.lower()  # 'JPEG'\n",
    "        \n",
    "        rgb_img = img.convert('RGB')\n",
    "        img.close()\n",
    "        \n",
    "        # Make new filenme to allign with text file name\n",
    "        filename = \"{}_{}.{}\".format(trainingData_term, idx, 'jpg')\n",
    "        newfilepath_f = os.path.join(os.path.dirname(f), filename)\n",
    "        \n",
    "        # Save and image\n",
    "        rgb_img.save(newfilepath_f)\n",
    "        os.remove(f)\n",
    "    \n",
    "    \n",
    "    return response \n",
    "\n",
    "img_args = {\"keywords\":\"photosynthesis\",\n",
    "             \"format\": \"png\",\n",
    "              \"limit\": numText_files,\n",
    "             \"output_directory\": 'data',\n",
    "            \"metadata\": True,\n",
    "            \"image_directory\": \"photosynthesis/images\",\n",
    "            \"no_download\": False,\n",
    "            \"extract_metadata\":True\n",
    "            # \"size\":\"icon\"\n",
    "           }\n",
    "\n",
    "response = download_images(trainingData_term, img_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txtFilenamesTo_pickle(flpth, lst_to_write):\n",
    "    \n",
    "    handle_missing_directories(os.path.dirname(flpth))\n",
    "    \n",
    "    pickle_out  = open(flpth, \"wb\")\n",
    "    pickle.dump(split_dict[splitType], pickle_out)\n",
    "    pickle_out.close()\n",
    "\n",
    "    return \n",
    "    \n",
    "def splitData(trainSplit, testSplit, filename_lst):\n",
    "    \n",
    "    # Calculate total number of filenames\n",
    "    num_filenames = len(filename_lst)\n",
    "\n",
    "    numTrain_files = np.ceil(trainSplit * num_filenames).astype(int)\n",
    "    numTest_files = np.floor(testSplit * num_filenames).astype(int)\n",
    "    \n",
    "    print(\"Number of Train files: {}\".format(numTrain_files))\n",
    "    print(\"Number of Test files: {}\".format(numTest_files))\n",
    "    \n",
    "    trainFile_lst = filename_lst[:numTrain_files]\n",
    "    testFile_lst = filename_lst[-numTrain_files:]\n",
    "    \n",
    "    return {\n",
    "        \"train\": trainFile_lst,\n",
    "        \"test\": testFile_lst\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text/photosynthesis_4'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def modified_txt_flpth(full_flpth):\n",
    "    # Read in filepath and seperate\n",
    "    p = pathlib.Path(full_flpth)\n",
    "    txtRel_flpth = p.relative_to(termTxtToImage_flpth)\n",
    "    txtCaption_flpth = str(txtRel_flpth.parent)\n",
    "    \n",
    "    txtFile_nm = txtRel_flpth.stem\n",
    "    #print(\"Filename: {}\".format(txtFile_nm))    \n",
    "    \n",
    "    \n",
    "    caption_flpth = os.path.join(txtCaption_flpth, txtFile_nm)\n",
    "    \n",
    "    return caption_flpth\n",
    "captionFilename = modified_txt_flpth('data/photosynthesis/text/photosynthesis_4.txt')\n",
    "captionFilename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Data Directory: data/photosynthesis/text\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['data/photosynthesis/text/photosynthesis_4.txt',\n",
       " 'data/photosynthesis/text/photosynthesis_0.txt',\n",
       " 'data/photosynthesis/text/photosynthesis_5.txt',\n",
       " 'data/photosynthesis/text/photosynthesis_6.txt',\n",
       " 'data/photosynthesis/text/photosynthesis_3.txt',\n",
       " 'data/photosynthesis/text/photosynthesis_1.txt',\n",
       " 'data/photosynthesis/text/photosynthesis_2.txt']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 7\n",
      "Number of Train files: 5\n",
      "Number of Test files: 2\n",
      "Pickling: data/photosynthesis/train/filenames.pickle \n",
      "Pickling: data/photosynthesis/test/filenames.pickle \n"
     ]
    }
   ],
   "source": [
    "# Define Text data directories\n",
    "text_flpth = os.path.join(termTxtToImage_flpth, 'text')\n",
    "print(\"Text Data Directory: {}\\n\".format(text_flpth))\n",
    "\n",
    "# Get all the file names from the text directory\n",
    "captionsFilename_lst = glob.glob(text_flpth+\"/**/*.txt\", recursive=True)\n",
    "modifiedCaptionsFilename_lst = [modified_txt_flpth(relCaption_flpth)  for relCaption_flpth in captionsFilename_lst]\n",
    "\n",
    "display(captions_filename_lst)\n",
    "print(\"Number of files: {}\".format(len(modifiedCaptionsFilename_lst)))\n",
    "\n",
    "\n",
    "# Split the data into training and test\n",
    "## Will need to accomodate term weightings and try different cossvalidation methods\n",
    "trainSplit = 0.7\n",
    "testSplit = 0.3\n",
    "\n",
    "split_dict = splitData(trainSplit, testSplit, modifiedCaptionsFilename_lst)\n",
    "\n",
    "# write files names to text and pickle\n",
    "for splitType in split_dict:\n",
    "    txtFlpth_pickle = os.path.join(termTxtToImage_flpth , splitType, 'filenames.pickle')\n",
    "    print('Pickling: {} '.format(txtFlpth_pickle))\n",
    "\n",
    "    txtFilenamesTo_pickle(txtFlpth_pickle, split_dict[splitType])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into training and test and \n",
    "Notes:\n",
    "    - I think in the original AttnGAN code `test` means `cross-validation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a text file for all of the caption filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the file names from the text directory\n",
    "captions_filename_lst = glob.glob(text_flpth+\"/**/*.txt\", recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/photosynthesis/text/photosynthesis_4.txt',\n",
       " 'data/photosynthesis/text/photosynthesis_0.txt',\n",
       " 'data/photosynthesis/text/photosynthesis_5.txt',\n",
       " 'data/photosynthesis/text/photosynthesis_6.txt',\n",
       " 'data/photosynthesis/text/photosynthesis_3.txt',\n",
       " 'data/photosynthesis/text/photosynthesis_1.txt',\n",
       " 'data/photosynthesis/text/photosynthesis_2.txt']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions_filename_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Data Directory: data/photosynthesis/text\n",
      "\n",
      "text\n",
      "text\n",
      "text\n",
      "text\n",
      "text\n",
      "text\n",
      "text\n"
     ]
    }
   ],
   "source": [
    "# Make a text file with a list of the caption filenames\n",
    "\n",
    "text_flpth = os.path.join(termTxtToImage_flpth, 'text')\n",
    "print(\"Text Data Directory: {}\\n\".format(text_flpth))\n",
    "\n",
    "# Find all the files with captions in the text directory and write there names to a file\n",
    "txtFile_lst = glob.glob(text_flpth+\"/**/*.txt\", recursive=True)\n",
    "\n",
    "writeFilename = \"{}.txt\".format('filenames')\n",
    "writeFilenames_flpth = os.path.join(termTxtToImage_flpth, writeFilename)\n",
    "\n",
    "\n",
    "# Write list to file in a form ATTN GAN accepts\n",
    "f =  open(writeFilenames_flpth, 'w')\n",
    "\n",
    "for item in txtFile_lst:\n",
    "    \n",
    "    \n",
    "    caption_flpth = modified_txt_flpth(item) \n",
    "        \n",
    "    f.write(\"{}\\n\".format(caption_flpth))\n",
    "    print (caption_flpth)\n",
    "    \n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "file must have 'read' and 'readline' attributes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-38fd654e4b34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtermTxtToImage_flpth\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"captions.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: file must have 'read' and 'readline' attributes"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "pickle.load(termTxtToImage_flpth+\"captions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'photosynthesis_2'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('text/photosynthesis_2.txt')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "txtRel_flpth = p.relative_to(termTxtToImage_flpth)\n",
    "txtRel_flpth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'photosynthesis_2'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileParts = txtRel_flpth.parts\n",
    "fileParts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.dirname(\"/home/ec2-user/environment/AttnGAN/data/photosynthesis/images/5. photosynthesis.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "s3Client = boto3.client(\"s3\")     \n",
    "s3Client.Object('my-bucket-name', 'newfile.txt').put(Body=content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(labels_corpus.docs[0].sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get(\"https://ssec.si.edu/stemvisions-blog/what-photosynthesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36-ml",
   "language": "python",
   "name": "py36-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
