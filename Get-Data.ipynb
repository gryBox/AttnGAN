{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "import boto3\n",
    "from boto3.dynamodb.conditions import Key\n",
    "import os\n",
    "from google_images_download import google_images_download\n",
    "import glob\n",
    "import PIL\n",
    "import json\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pickle\n",
    "\n",
    "import textacy\n",
    "import en_core_web_sm\n",
    "\n",
    "\n",
    "#import code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/environment/AttnGAN/get_model_training_data'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "os.path.join(cwd, 'get_model_training_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Text Data for inputTerm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputTerm = 'photosynthesis'\n",
    "topic ='biology'\n",
    "\n",
    "\n",
    "tblName = \"ResourceDocuments\"\n",
    "nodeIdentifierName = \"photosynthesis-photosynthesis-photosynthesis-biology\"\n",
    "\n",
    "termTxtToImage_flpth = 'data/photosynthesis'\n",
    "text_flpth = os.path.join(termTxtToImage_flpth, 'text')\n",
    "img_flpth =  os.path.join(termTxtToImage_flpth, 'images')\n",
    "imageLog_fir='logs'\n",
    "\n",
    "resourceDbName = 'dynamodb'\n",
    "#s3Bucket = \"egm-bucket/TEXT_TO_IMAGE_DATA/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data from Resource Db: \n",
    "photosynthesis whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NUmber of Items in ResourceDb: 14'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Definitions for photosynthesis from dynamodb\n",
    "\n",
    "## Connect to dynamodb\n",
    "dynamodbClient = boto3.resource(\"dynamodb\")\n",
    "# client = boto3.client('dynamodb')\n",
    "# display(client.describe_table(TableName=tblName))\n",
    "\n",
    "## Connect to table with resources\n",
    "resourceTbl = dynamodbClient.Table(tblName)\n",
    "# display(resourceTbl.global_secondary_indexes)\n",
    "display(\"NUmber of Items in ResourceDb: {}\".format(resourceTbl.item_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load text into pandas \n",
    "- For data munging\n",
    "    - stats\n",
    "    - Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Db Response Shape: (14, 13)\n",
      "Db Response Shape: (7, 13)\n",
      "Index(['IMAGES', 'NODE_IDENTIFIER', 'POS', 'RESOURCE', 'RESOURCE_ATTRIBUTION',\n",
      "       'RESOURCE_DATATYPE', 'RESOURCE_SOURCE', 'RESOURCE_TYPE', 'RESOURCE_URL',\n",
      "       'TERM', 'TIME_DOWNLOADED', 'TOPIC', 'UNIQUE_IDENTIFIER'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "response = resourceTbl.query(\n",
    "    IndexName='NODE_IDENTIFIER-index',\n",
    "    KeyConditionExpression=Key('NODE_IDENTIFIER').eq(nodeIdentifierName)\n",
    ")\n",
    "\n",
    "# Pass through pandas for some data munging\n",
    "rsrc_df = pd.DataFrame(response[\"Items\"])\n",
    "print(\"Db Response Shape: {}\".format(rsrc_df.shape))\n",
    "\n",
    "rsrc_df.drop_duplicates(['RESOURCE'], keep='last', inplace=True)\n",
    "rsrc_df.reset_index(drop=True)\n",
    "\n",
    "print(\"Db Response Shape: {}\".format(rsrc_df.shape))\n",
    "print(rsrc_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4        century\n",
       "5        wordnet\n",
       "9     wiktionary\n",
       "10     wikipedia\n",
       "11         gcide\n",
       "12     wikipedia\n",
       "13    ahd-legacy\n",
       "Name: RESOURCE_SOURCE, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsrc_df[\"RESOURCE_SOURCE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load text from s3 to df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "inputTerm_lst = ['photosynthesis', 'sun', 'water']\n",
    "\n",
    "inputTerm_df_lst = []\n",
    "for inputTerm in inputTerm_lst:\n",
    "    nodeIdentifierName = \"{}-{}-{}-{}\".format(inputTerm, inputTerm, inputTerm, topic)\n",
    "    s3key = \"NODE-DATASTORE-TMP/{}/normedFedSearch.json\".format(nodeIdentifierName)\n",
    "    s3 = boto3.client('s3')\n",
    "    result = s3.get_object(Bucket='egm-bucket', Key=s3key)\n",
    "    file_content = result['Body'].read().decode('utf-8')\n",
    "    json_content = json.loads(file_content)\n",
    "    df = pd.DataFrame(json_content)\n",
    "    inputTerm_df_lst.append(df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "captions_df = pd.concat(inputTerm_df_lst)\n",
    "captions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest corpus data from df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_corpus(df):\n",
    "    # Load into textacy to delimit sentences\n",
    "    img_labels = df.to_dict(orient=\"records\")\n",
    "    text_stream, metadata_stream = textacy.io.split_records(img_labels, 'RESOURCE')\n",
    "\n",
    "    # Load english model\n",
    "    en = en_core_web_sm.load()\n",
    "    corpus = textacy.Corpus(lang=en, texts=text_stream, metadatas=metadata_stream)\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Doc(37 tokens; \"A chemical combination brought about by the act...\"),\n",
       " Doc(14 tokens; \"synthesis of compounds with the aid of radiant ...\"),\n",
       " Doc(24 tokens; \"The process by which plants and other photoauto...\"),\n",
       " Doc(512 tokens; \"Photosynthesis is a process used by plants and ...\"),\n",
       " Doc(200 tokens; \"The process of constructive metabolism by which...\"),\n",
       " Doc(140 tokens; \"Photosynthesis is a process used by plants and ...\"),\n",
       " Doc(36 tokens; \"The process in green plants and certain other o...\")]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captionsCorpus = df_to_corpus(rsrc_df)\n",
    "captionsCorpus.docs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "captionsCorpus.docs.Docs.n_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformText_to_captions(txtDoc, numCaptions_per_image=5, txtSplit_method='svo'):\n",
    "    # Take textacy doc and converts to a list of captions for an image\n",
    "    \n",
    "    if txtSplit_method=='noun_chunks':\n",
    "        split_list = list(textacy.extract.noun_chunks(txtDoc, drop_determiners=False, min_freq=1))\n",
    "    if txtSplit_method=='svo':\n",
    "        split_list = list(textacy.extract.subject_verb_object_triples(txtDoc))\n",
    "    \n",
    "    return split_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest Doc number of tokens 14\n"
     ]
    }
   ],
   "source": [
    "# 1  Find the document with the min number of tokens\n",
    "minToken_num = min([doc.n_tokens for doc in captionsCorpus])\n",
    "print(f\"Shortest Doc number of tokens {minToken_num}\")\n",
    "\n",
    "shortestDocs = captionsCorpus.get(lambda x: len(x)==minToken_num)\n",
    "shortestDoc = list(shortestDocs)[0]\n",
    "# 2  Find the maximum amount of captions that can be made for the shortest doc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Doc(14 tokens; \"synthesis of compounds with the aid of radiant ...\")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortestDoc\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Make captions for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'noun_chunks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-eb489e234e80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoun_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshortestDoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_determiners\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py36-ml/lib/python3.6/site-packages/textacy/extract.py\u001b[0m in \u001b[0;36mnoun_chunks\u001b[0;34m(doc, drop_determiners, min_freq)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mncs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspacy_doc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoun_chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0mncs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoun_chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdrop_determiners\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0mncs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnc\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mDET\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mncs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'noun_chunks'"
     ]
    }
   ],
   "source": [
    "list(textacy.extract.noun_chunks(txtDoc, drop_determiners=False, min_freq=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txtDoc = imgTxt_corpus[0]\n",
    "txtDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgTxt_corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgTxt_corpus.get(lambda x: len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docSplit_list = transformText_to_captions(txtDoc, numCaptions_per_image=5, txtSplit_method='svo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(textacy.extract.ngrams(txtDoc, n=5, filter_stops=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txtDoc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textacy.extract.acronyms_and_definitions(txtDoc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Maximize the number of captions in the doc with the minimum number tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minToken_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Doc(14 tokens; \"synthesis of compounds with the aid of radiant ...\")]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(shortestDoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc(14 tokens; \"synthesis of compounds with the aid of radiant ...\")\n"
     ]
    }
   ],
   "source": [
    "for i in k:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Labels for text to image model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_directories(directory_flpth):\n",
    "    # Handle missing Directory\n",
    "    if not os.path.exists(directory_flpth):\n",
    "        \n",
    "        os.makedirs(directory_flpth)\n",
    "        print(\"Made new directory: {}\".format(directory_flpth))\n",
    "        # print(os.path.join(dirname, flpth))\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return\n",
    "\n",
    "# Create text file for each doc - Each Doc maps to an image\n",
    "\n",
    "## TODO: incoroporate number of labals per line\n",
    "def labels_to_imageTxt_files(rsrc_df, trainingData_term, trainigData_flpth='../data'):\n",
    "    \n",
    "    # Handle if a data directory for a term exists e.g. data/photosynthesis\n",
    "    dirname = os.path.abspath('')\n",
    "    termData_flpth = os.path.join(dirname, trainigData_flpth)\n",
    "    handle_missing_directories(termData_flpth)\n",
    "    \n",
    "    \n",
    "    ### Move resource df to textacy\n",
    "   \n",
    "    # Load into textacy to delimit sentences\n",
    "    img_labels = rsrc_df.to_dict(orient=\"records\")\n",
    "    text_stream, metadata_stream = textacy.io.split_records(img_labels, 'RESOURCE')\n",
    "\n",
    "    # Load english model\n",
    "    en = en_core_web_sm.load()\n",
    "    labels_corpus = textacy.Corpus(lang=en, texts=text_stream, metadatas=metadata_stream)\n",
    "    \n",
    "    caption_filename_path = os.path.join(trainigData_flpth, \"captions.pickle\")\n",
    "    \n",
    "    # Loop through corpus and write document to flpth (s3)\n",
    "    ''' Each doc in a corpus equals and image'''\n",
    "    for ix, doc in enumerate(labels_corpus):\n",
    "        print(\"Number of Sentences: {}\".format(doc.n_sents))\n",
    "        \n",
    "        # Paths to directories (Where to write the text files)\n",
    "        filename = \"{}_{}.txt\".format(trainingData_term, ix)\n",
    "        path_to_file = \"{}/{}\".format(trainigData_flpth, filename)\n",
    "        \n",
    "        # Write captions for google images\n",
    "        f =  open(path_to_file, 'w')\n",
    "        \n",
    "        # Parse Document into sentences\n",
    "        for sent in doc.sents:\n",
    "            caption = textacy.preprocess.preprocess_text(sent.text,\n",
    "                                               lowercase=True,\n",
    "                                               no_punct=True\n",
    "                                              )\n",
    "            # f.write(label+\"\\n\" )\n",
    "            f.write(caption+\" \" )\n",
    "            \n",
    "        f.close()\n",
    "        \n",
    "    return ix + 1 # Count using 1 as start\n",
    "\n",
    "# process labels for images\n",
    "\n",
    "\n",
    "trainingData_term = 'photosynthesis'\n",
    "txt_trainingData_flpth='{}/text'.format(termTxtToImage_flpth, 'text')\n",
    "\n",
    "numText_files = labels_to_imageTxt_files(rsrc_df, trainingData_term, txt_trainingData_flpth)\n",
    "numText_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Images from google "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainingData_term' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-ae5898de15de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m            }\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingData_term\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainingData_term' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def download_images(term ,img_args):\n",
    "    \n",
    "    # Download Images \n",
    "    response = google_images_download.googleimagesdownload()\n",
    "    img_paths = response.download(img_args)\n",
    "    \n",
    "    # Post Process google image results\n",
    "    for idx, f in enumerate(img_paths[term]):\n",
    "        \n",
    "        # Open Google image resulst and conver to jpeg\n",
    "        img = PIL.Image.open(f)\n",
    "        img_filetype = img.format.lower()  # 'JPEG'\n",
    "        \n",
    "        rgb_img = img.convert('RGB')\n",
    "        img.close()\n",
    "        \n",
    "        # Make new filenme to allign with text file name\n",
    "        filename = \"{}_{}.{}\".format(trainingData_term, idx, 'jpg')\n",
    "        newfilepath_f = os.path.join(os.path.dirname(f), filename)\n",
    "        \n",
    "        # Save and image\n",
    "        rgb_img.save(newfilepath_f)\n",
    "        os.remove(f)\n",
    "    \n",
    "    \n",
    "    return response \n",
    "\n",
    "img_args = {\"keywords\":\"sun\",\n",
    "             \"format\": \"png\",\n",
    "              \"limit\": 20,\n",
    "             \"output_directory\": 'data',\n",
    "            \"metadata\": True,\n",
    "            \"image_directory\": \"photosynthesis/images\",\n",
    "            \"no_download\": False,\n",
    "            \"extract_metadata\":True\n",
    "            # \"size\":\"icon\"\n",
    "           }\n",
    "\n",
    "response = download_images(trainingData_term, img_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tigDataLoader.utiils as dataloader\n",
    "import os\n",
    "import json\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictTerm = \"photosynthesis\"\n",
    "dataTerm = \"photosynthesis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base file io inputs\n",
    "trainData_flpth = os.path.join('data', predictTerm)\n",
    "text_flpth = os.path.join(trainData_flpth, 'text')\n",
    "img_flpth =  os.path.join(trainData_flpth, 'images')\n",
    "\n",
    "# Google imagae download metadata\n",
    "imageLog_fir='logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformText_to_captions(txtDoc, numCaptions_per_image=5, txtSplit_method='svo'):\n",
    "    # Take textacy doc and converts to a list of captions for an image\n",
    "    \n",
    "    if txtSplit_method=='noun_chunks':\n",
    "        split_list = list(textacy.extract.noun_chunks(txtDoc, drop_determiners=False, min_freq=1))\n",
    "    if txtSplit_method=='svo':\n",
    "        split_list = list(textacy.extract.subject_verb_object_triples(txtDoc))\n",
    "    \n",
    "    return split_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Download images\n",
    "- from google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_args = {\"keywords\": dataTerm,\n",
    "             \"format\": \"png\",\n",
    "              \"limit\": 100,\n",
    "             \"output_directory\": 'data',\n",
    "            \"metadata\": True,\n",
    "            \"image_directory\": \"{}/images/\".format(predictTerm),\n",
    "            \"no_download\": False,\n",
    "            \"extract_metadata\":True,\n",
    "            \"type\": \"clipart\"\n",
    "           }\n",
    "img_paths, response = dataloader.download_images(dataTerm, img_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download text from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load text into textacy\n",
    "imgTxt_corpus = df_to_corpus()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(labels_corpus.docs[0].sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get(\"https://ssec.si.edu/stemvisions-blog/what-photosynthesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Fake data\n",
    "import shutil\n",
    "import itertools\n",
    "\n",
    "# Get a list of the original files f\n",
    "txtDirFileNm_lst = glob.glob(text_flpth+\"/**/*.txt\", recursive=True)\n",
    "imgDirFileNm_lst = glob.glob(img_flpth+\"/**/*.jpg\", recursive=True)\n",
    "\n",
    "fileCombo_lst = list(itertools.product(txtDirFileNm_lst,imgDirFileNm_lst))\n",
    "\n",
    "# for item in fileCombo_lst:\n",
    "    \n",
    "#     # Get text name\n",
    "#     txtget_relfilename\n",
    "\n",
    "# # # Create list paired tuple pairs\n",
    "# # comboFlpth_lst = list(zip(txtDirFileNm_lst, imgDirFileNm_lst))\n",
    "# # comboFlpth_lst\n",
    "\n",
    "# # new_list = []\n",
    "# # for k,v in comboFlpth_lst.iteritems():\n",
    "# #     new_list.extend([x for x in combinations(v, 2)]) \n",
    "# # # for txtFile, imgFile in comboFlpth_dict:\n",
    "# # #     # Make copies of files and rename\n",
    "# # #     shutil.copyfile(txtFile, dst)\n",
    "# # #     shutil.copyfile(imgFile, dst)\n",
    "\n",
    "# # new_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 18)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "df = pd.read_csv(\"RUNS.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.relplot(x=\"s_loss\", y=\"embedding_dim\", data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36-ml",
   "language": "python",
   "name": "py36-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
