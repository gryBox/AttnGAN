{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "# import pandas as pd\n",
    "# import io\n",
    "# import boto3\n",
    "# from boto3.dynamodb.conditions import Key\n",
    "# import os\n",
    "# from google_images_download import google_images_download\n",
    "# import glob\n",
    "# import PIL\n",
    "# import json\n",
    "# import numpy as np\n",
    "# import pathlib\n",
    "# import pickle\n",
    "\n",
    "# import textacy\n",
    "# import en_core_web_sm\n",
    "\n",
    "import code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data files to train the models with a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function code.interact(banner=None, readfunc=None, local=None, exitmsg=None)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tblName = \"ResourceDocuments\"\n",
    "nodeIdentifierName = \"photosynthesis-photosynthesis-photosynthesis-biology\"\n",
    "\n",
    "termTxtToImage_flpth = 'data/photosynthesis'\n",
    "text_flpth = os.path.join(termTxtToImage_flpth, 'text')\n",
    "img_flpth =  os.path.join(termTxtToImage_flpth, 'images')\n",
    "imageLog_fir='logs'\n",
    "\n",
    "resourceDbName = 'dynamodb'\n",
    "s3Bucket = \"egm-bucket/TEXT_TO_IMAGE_DATA/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data from Resource Db: \n",
    "photosynthesis whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Definitions for photosynthesis from dynamodb\n",
    "\n",
    "## Connect to dynamodb\n",
    "dynamodbClient = boto3.resource(\"dynamodb\")\n",
    "# client = boto3.client('dynamodb')\n",
    "# display(client.describe_table(TableName=tblName))\n",
    "\n",
    "## Connect to table with resources\n",
    "resourceTbl = dynamodbClient.Table(tblName)\n",
    "# display(resourceTbl.global_secondary_indexes)\n",
    "display(\"NUmber of Items in ResourceDb: {}\".format(resourceTbl.item_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load text into pandas \n",
    "- For data munging\n",
    "    - stats\n",
    "    - Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = resourceTbl.query(\n",
    "    IndexName='NODE_IDENTIFIER-index',\n",
    "    KeyConditionExpression=Key('NODE_IDENTIFIER').eq(nodeIdentifierName)\n",
    ")\n",
    "\n",
    "# Pass through pandas for some data munging\n",
    "rsrc_df = pd.DataFrame(response[\"Items\"])\n",
    "print(\"Db Response Shape: {}\".format(rsrc_df.shape))\n",
    "\n",
    "rsrc_df.drop_duplicates(['RESOURCE'], keep='last', inplace=True)\n",
    "rsrc_df.reset_index(drop=True)\n",
    "\n",
    "print(\"Db Response Shape: {}\".format(rsrc_df.shape))\n",
    "print(rsrc_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsrc_df[\"RESOURCE_SOURCE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Labels for text to image model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oxf = \"The process by which green plants and some other organisms use sunlight to synthesize nutrients from carbon dioxide and water. Photosynthesis in plants generally involves the green pigment chlorophyll and generates oxygen as a by-product.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsrc_df.append(pd.DataFrame({\"RESOURCE_SOURCE\": [oxf]}, sort=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_directories(directory_flpth):\n",
    "    # Handle missing Directory\n",
    "    if not os.path.exists(directory_flpth):\n",
    "        \n",
    "        os.makedirs(directory_flpth)\n",
    "        print(\"Made new directory: {}\".format(directory_flpth))\n",
    "        # print(os.path.join(dirname, flpth))\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return\n",
    "\n",
    "# Create text file for each doc - Each Doc maps to an image\n",
    "\n",
    "## TODO: incoroporate number of labals per line\n",
    "def labels_to_imageTxt_files(rsrc_df, trainingData_term, trainigData_flpth='../data'):\n",
    "    \n",
    "    # Handle if a data directory for a term exists e.g. data/photosynthesis\n",
    "    dirname = os.path.abspath('')\n",
    "    termData_flpth = os.path.join(dirname, trainigData_flpth)\n",
    "    handle_missing_directories(termData_flpth)\n",
    "    \n",
    "    \n",
    "    ### Move resource df to textacy\n",
    "   \n",
    "    # Load into textacy to delimit sentences\n",
    "    img_labels = rsrc_df.to_dict(orient=\"records\")\n",
    "    text_stream, metadata_stream = textacy.io.split_records(img_labels, 'RESOURCE')\n",
    "\n",
    "    # Load english model\n",
    "    en = en_core_web_sm.load()\n",
    "    labels_corpus = textacy.Corpus(lang=en, texts=text_stream, metadatas=metadata_stream)\n",
    "    \n",
    "    caption_filename_path = os.path.join(trainigData_flpth, \"captions.pickle\")\n",
    "    \n",
    "    # Loop through corpus and write document to flpth (s3)\n",
    "    ''' Each doc in a corpus equals and image'''\n",
    "    for ix, doc in enumerate(labels_corpus):\n",
    "        print(\"Number of Sentences: {}\".format(doc.n_sents))\n",
    "        \n",
    "        # Paths to directories (Where to write the text files)\n",
    "        filename = \"{}_{}.txt\".format(trainingData_term, ix)\n",
    "        path_to_file = \"{}/{}\".format(trainigData_flpth, filename)\n",
    "        \n",
    "        # Write captions for google images\n",
    "        f =  open(path_to_file, 'w')\n",
    "        \n",
    "        # Parse Document into sentences\n",
    "        for sent in doc.sents:\n",
    "            caption = textacy.preprocess.preprocess_text(sent.text,\n",
    "                                               lowercase=True,\n",
    "                                               no_punct=True\n",
    "                                              )\n",
    "            # f.write(label+\"\\n\" )\n",
    "            f.write(caption+\" \" )\n",
    "            \n",
    "        f.close()\n",
    "        \n",
    "    return ix + 1 # Count using 1 as start\n",
    "\n",
    "# process labels for images\n",
    "\n",
    "\n",
    "trainingData_term = 'photosynthesis'\n",
    "txt_trainingData_flpth='{}/text'.format(termTxtToImage_flpth, 'text')\n",
    "\n",
    "numText_files = labels_to_imageTxt_files(rsrc_df, trainingData_term, txt_trainingData_flpth)\n",
    "numText_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Images from google "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_images(term ,img_args):\n",
    "    \n",
    "    # Download Images \n",
    "    response = google_images_download.googleimagesdownload()\n",
    "    img_paths = response.download(img_args)\n",
    "    \n",
    "#     # Post Process google image results\n",
    "#     for idx, f in enumerate(img_paths[term]):\n",
    "        \n",
    "#         # Open Google image resulst and conver to jpeg\n",
    "#         img = PIL.Image.open(f)\n",
    "#         img_filetype = img.format.lower()  # 'JPEG'\n",
    "        \n",
    "#         rgb_img = img.convert('RGB')\n",
    "#         img.close()\n",
    "        \n",
    "#         # Make new filenme to allign with text file name\n",
    "#         filename = \"{}_{}.{}\".format(trainingData_term, idx, 'jpg')\n",
    "#         newfilepath_f = os.path.join(os.path.dirname(f), filename)\n",
    "        \n",
    "#         # Save and image\n",
    "#         rgb_img.save(newfilepath_f)\n",
    "#         os.remove(f)\n",
    "    \n",
    "    \n",
    "    return response \n",
    "\n",
    "img_args = {\"keywords\":\"sun\",\n",
    "             \"format\": \"png\",\n",
    "              \"limit\": 100,\n",
    "             \"output_directory\": 'data',\n",
    "            \"metadata\": True,\n",
    "            \"image_directory\": \"photosynthesis/images\",\n",
    "            \"no_download\": False,\n",
    "            \"extract_metadata\":True\n",
    "            # \"size\":\"icon\"\n",
    "           }\n",
    "\n",
    "response = download_images(trainingData_term, img_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tigDataLoader.utiils as dataloader\n",
    "import os\n",
    "import json\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictTerm = \"photosynthesis\"\n",
    "dataTerm = \"photosynthesis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base file io inputs\n",
    "trainData_flpth = os.path.join('data', predictTerm)\n",
    "text_flpth = os.path.join(trainData_flpth, 'text')\n",
    "img_flpth =  os.path.join(trainData_flpth, 'images')\n",
    "\n",
    "# Google imagae download metadata\n",
    "imageLog_fir='logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformText_to_captions(txtDoc, numCaptions_per_image=5, txtSplit_method='svo'):\n",
    "    # Take textacy doc and converts to a list of captions for an image\n",
    "    \n",
    "    if txtSplit_method=='noun_chunks':\n",
    "        split_list = list(textacy.extract.noun_chunks(txtDoc, drop_determiners=False, min_freq=1))\n",
    "    if txtSplit_method=='svo':\n",
    "        split_list = list(textacy.extract.subject_verb_object_triples(txtDoc))\n",
    "    \n",
    "    return split_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Make captions for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load text to textacy - each document is linked to an image\n",
    "imgTxt_corpus = dataloader.df_to_corpus(rsrc_df)\n",
    "imgTxt_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/AttnGAN/data/photosynthesis/captions.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgTxt_corpus[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgTxt_corpus.word_doc_freqs(normalize='lemma', weighting='count', as_strings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txtDoc = imgTxt_corpus[0]\n",
    "txtDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgTxt_corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgTxt_corpus.get(lambda x: len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docSplit_list = transformText_to_captions(txtDoc, numCaptions_per_image=5, txtSplit_method='svo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(textacy.extract.ngrams(txtDoc, n=5, filter_stops=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txtDoc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textacy.extract.acronyms_and_definitions(txtDoc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Maximize the number of captions in the doc with the minimum number tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Download images\n",
    "- from google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_args = {\"keywords\": dataTerm,\n",
    "             \"format\": \"png\",\n",
    "              \"limit\": 100,\n",
    "             \"output_directory\": 'data',\n",
    "            \"metadata\": True,\n",
    "            \"image_directory\": \"{}/images/\".format(predictTerm),\n",
    "            \"no_download\": False,\n",
    "            \"extract_metadata\":True,\n",
    "            \"type\": \"clipart\"\n",
    "           }\n",
    "img_paths, response = dataloader.download_images(dataTerm, img_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load text into textacy\n",
    "imgTxt_corpus = df_to_corpus()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load image meta-data json \n",
    "with open('coco/logs/sun.json') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitDir = 'train'\n",
    "with open(os.path.join(termTxtToImage_flpth, splitDir, \"filenames.pickle\"), \"rb\") as pickF:\n",
    "    tstFilenames = pickle.load(pickF)\n",
    "    \n",
    "display(type(tstFilenames),\n",
    "        len(tstFilenames),\n",
    "        tstFilenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstFilenames[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitDir = 'test'\n",
    "with open(os.path.join(termTxtToImage_flpth, splitDir, \"filenames.pickle\"), \"rb\") as pickF:\n",
    "    tstFilenames = pickle.load(pickF)\n",
    "    \n",
    "display(type(tstFilenames),\n",
    "        len(tstFilenames),\n",
    "        tstFilenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/photosynthesis/train/filenames.pickle\", \"rb\") as pickF:\n",
    "    trFilenames = pickle.load(pickF)\n",
    "    \n",
    "display(type(trFilenames),\n",
    "        len(trFilenames),\n",
    "        trFilenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonalities = set(trFilenames) - (set(trFilenames) - set(tstFilenames))\n",
    "commonalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.dirname(\"/home/ec2-user/environment/AttnGAN/data/photosynthesis/images/5. photosynthesis.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "s3Client = boto3.client(\"s3\")     \n",
    "s3Client.Object('my-bucket-name', 'newfile.txt').put(Body=content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(labels_corpus.docs[0].sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get(\"https://ssec.si.edu/stemvisions-blog/what-photosynthesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Fake data\n",
    "import shutil\n",
    "import itertools\n",
    "\n",
    "# Get a list of the original files f\n",
    "txtDirFileNm_lst = glob.glob(text_flpth+\"/**/*.txt\", recursive=True)\n",
    "imgDirFileNm_lst = glob.glob(img_flpth+\"/**/*.jpg\", recursive=True)\n",
    "\n",
    "fileCombo_lst = list(itertools.product(txtDirFileNm_lst,imgDirFileNm_lst))\n",
    "\n",
    "# for item in fileCombo_lst:\n",
    "    \n",
    "#     # Get text name\n",
    "#     txtget_relfilename\n",
    "\n",
    "# # # Create list paired tuple pairs\n",
    "# # comboFlpth_lst = list(zip(txtDirFileNm_lst, imgDirFileNm_lst))\n",
    "# # comboFlpth_lst\n",
    "\n",
    "# # new_list = []\n",
    "# # for k,v in comboFlpth_lst.iteritems():\n",
    "# #     new_list.extend([x for x in combinations(v, 2)]) \n",
    "# # # for txtFile, imgFile in comboFlpth_dict:\n",
    "# # #     # Make copies of files and rename\n",
    "# # #     shutil.copyfile(txtFile, dst)\n",
    "# # #     shutil.copyfile(imgFile, dst)\n",
    "\n",
    "# # new_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36-ml",
   "language": "python",
   "name": "py36-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
