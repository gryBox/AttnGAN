- model: damsm
  description: Deep Attentional Multimodal Similarity Model (DAMSM)
  operations:

    pretrain:
      description: Pretrain the DAMSM model
      main: pretrain_DAMSM --data_dir data/photosynthesis --output_dir output --cfg cfg/DAMSM/photosynthesis.yml
      flags-import: no

      flags:
        epochs:
          description: Number of epochs to run
          arg-name: max_epoch
          default: 201  # So the last trained model can be captured
        gamma1:
          description: Smooth gamma1
          default: 72.4953
          type: float
        gamma2:
          description: Smooth gamma2
          default: 65.3585
          type: float
        gamma3:
          description: Smooth gamma3
          default: 50.0
          type: float
        encoder_lr:
          description: ENCODER_LR
          default: 0.003189
          type: float
        embedding_dim:
          description: EMBEDDING_DIM
          default: 1024
          type: int
        rnn_grad_clip:
          description: RNN_GRAD_CLIP
          default: 2.0
          type: float
        captions_per_image:
          description: CAPTIONS_PER_IMAGE
          default: 1
          type: int
        words_num:
          description: WORDS_NUM
          default: 244
          type: int

      requires:
        - file: ../data
        - file: cfg

      output-scalars:
        step: 'end epoch +([0-9]+)'
        s_loss: 'valid loss +([0-9\.]+)'
        w_loss: 'valid loss +[0-9\.]+ +([0-9\.]+)'

      compare:
        - s_loss step as step
        - s_loss
        - w_loss
        - =epochs
        - =embedding_dim
        - =captions_per_image
        - =words_num
        - =gamma1
        - =gamma2
        - =gamma3
        - =encoder_lr
        - =rnn_grad_clip
        
      objective: s_loss

    # train:
    # train:
    #   description: Pretrain the DAMSM model
    #   main: pretrain_DAMSM --data_dir data/photosynthesis --output_dir output --cfg cfg/photosynthesis_attn2
    #   flags-import: no

    #   flags:
    #     epochs:
    #       description: Number of epochs to run
    #       arg-name: max_epoch
    #       default: 201  # So the last trained model can be captured
    #     gamma1:
    #       description: Smooth gamma1
    #       default: 72.4953
    #       type: float
    #     gamma2:
    #       description: Smooth gamma2
    #       default: 65.3585
    #       type: float
    #     gamma3:
    #       description: Smooth gamma3
    #       default: 50.0
    #       type: float
    #     encoder_lr:
    #       description: ENCODER_LR
    #       default: 0.003189
    #       type: float
    #     embedding_dim:
    #       description: EMBEDDING_DIM
    #       default: 1024
    #       type: int
    #     rnn_grad_clip:
    #       description: RNN_GRAD_CLIP
    #       default: 2.0
    #       type: float
    #     captions_per_image:
    #       description: CAPTIONS_PER_IMAGE
    #       default: 1
    #       type: int

    #   requires:
    #     - file: ../data
    #     - file: cfg

    #   output-scalars:
    #     step: 'end epoch +([0-9]+)'
    #     s_loss: 'valid loss +([0-9\.]+)'
    #     w_loss: 'valid loss +[0-9\.]+ +([0-9\.]+)'

    #   compare:
    #     - s_loss step as step
    #     - s_loss
    #     - w_loss
    #     - =epochs
    #     - =captions_per_image
    #     - =gamma1
    #     - =gamma2
    #     - =gamma3
    #     - =encoder_lr
    #     - =embedding_dim
    #     - =rnn_grad_clip
        
    #   objective: s_loss

    #all:
    #  description: Run all steps for building model start to finish
    #  steps:
    #    - run: pretrain
    #    #- run: train
