# TODO
#
# - Verify/cleanup flag descriptions
#
# - Consider creating a symlink to last generated pth file
#   whenever writing such files (e.g. latest.pth). Then
#   change the default path to latest in CFG support. This
#   is a simpler, more typical approach to solving this
#   problem.

- config: shared-flags
  flags:
    epochs:
      description: Number of epochs to run
      arg-name: max_epoch
    batch_size:
      description: Training batch size
      default: 7
    gamma1:
      description: Smooth gamma1
      default: 72.4953
    gamma2:
      description: Smooth gamma2
      default: 65.3585
    gamma3:
      description: Smooth gamma3
      default: 89.2507
    embedding_dim:
      description: Embedding dimension
      default: 128
    captions_per_image:
      description: Number of captions per image
      default: 1
    words_num:
      description: Number of words per caption
      default: 244

- config: pretrain-flags
  flags:
    delete_captions_pickle:
      description: Force re-create of captions pickle
      default: yes
    train_split:
      description: Ratio of data used for training
      default: 1.0
    validation_split:
      description: Ration of data used for validation
      default: 1.0
    encoder_lr:
      description: Encoder learning rate
      default: 0.003189
    rnn_grad_clip:
      description: RNN gradient clip
      default: 2.0

- config: train-flags
  flags:
    discriminator_lr:
      description: Discriminator learning rate
      default: 0.0002
    generator_lr:
      description: Generator learning rate
      default: 0.0002
    lambda_a:
      description: Lambda A
      default: 50
    df_dim:
      description: DF dimension
      default: 96
    gf_dim:
      description: GF dimension
      default: 48
    z_dim:
      description: X dimension
      default: 100
    r_num:
      description: R
      default: 3

- config: evaluate-flags
  flags:
    b_net_d:
      description: Boolean flag #(todo: get description)
      default: False

- model: damsm
  description: Deep Attentional Multimodal Similarity Model (DAMSM)

  resources:
    config:
      sources:
        - file: cfg
    data:
      sources:
        - file: ../data/photosynthesis

    pretrained-model:
      path: nets
      sources:
        - operation: pretrain
          select: .+\.pth

    trained-model:
      path: nets
      sources:
        - operation: train
          select: .+\.pth

  operations:
    pretrain:
      description: Pretrain the DAMSM model

      main: pretrain_DAMSM
             --data_dir photosynthesis
             --output_dir output
             --cfg cfg/DAMSM/photosynthesis.yml

      requires:
        - config
        - data

      flags-import: no
      flags:
        $include:
          - shared-flags
          - pretrain-flags

        # Uncomment below to override flag defaults for pretrain
        # epochs: 201
        # gamma1: 72.4953
        # gamma2: 65.3585
        # gamma3: 89.2507
        # encoder_lr: 0.003189
        # embedding_dim: 128
        # rnn_grad_clip: 2.0
        # captions_per_image: 1
        # words_num: 244

      output-scalars:
        step: 'end epoch +([0-9]+)'
        s_loss: 'valid loss +([0-9\.]+)'
        w_loss: 'valid loss +[0-9\.]+ +([0-9\.]+)'

      objective: w_loss

    train:
      description: Train the DAMSM model

      main: main
             --data_dir photosynthesis
             --model_dir nets
             --output_dir output
             --net_e latest
             --cfg cfg/photosynthesis_attn2.yml

      requires:
        - config
        - data
        - pretrained-model

      flags-import: no
      flags:
        $include:
          - shared-flags
          - train-flags

      output-scalars:
        step: 'Step: ([0-9]+)'
        errD0: 'errD0: (\S+)'
        errD1: 'errD1: (\S+)'
        errD2: 'errD2: (\S+)'
        g_loss0: 'g_loss0: (\S+)'
        g_loss1: 'g_loss1: (\S+)'
        g_loss2: 'g_loss2: (\S+)'
        w_loss: 'w_loss: (\S+)'
        s_loss: 's_loss: (\S+)'
        kl_loss: 'kl_loss: (\S+)'

      objective: w_loss

    evaluate:
      description: Predict on trained model
      main: main
             --model_dir nets
             --data_dir data/photosynthesis
             --cfg cfg/eval_photosynthesis.yml

      requires:
        - config
        - data
        - pretrained-model
        - trained-model

      flags-import: no
      flags:
        $include:
          - shared-flags
          - evaluate-flags

    _check:
      steps:
        - run: pretrain epochs=1
        - run: train epochs=1
        - run: evaluate
