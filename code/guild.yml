# -------------------------------------------------------------------
# Shared flags
# -------------------------------------------------------------------

- config: common-flags
  description: Commonly used flags across operations
  flags:
    gpu:
      description: Index of CUDA device to run operation on
      default: 0
    batch_size:
      description: Training batch size
      default: 7
    embedding_dim:
      description: Embedding dimension
      default: 256
    captions_per_image:
      description: Number of captions per image
      default: 1
    words_num:
      description: Number of words per caption
      default: 15

- config: dataset-flags
  description: Flags used by data set dependent operations
  flags:
    dataset:
      description: Dataset to pretrain
      default: photosynthesis
      choices:
        - photosynthesis
        - birds
      arg-skip: yes
      required: yes

- config: pretrain-train-flags
  description: Flags used by both pretrain and train
  flags:
    epochs:
      description: Number of epochs to run
      arg-name: max_epoch
      default: 301
    snapshot-interval:
      description: Number of epochs per snapshot
      default: 300
    train_split:
      description: Ratio of data used for training
      default: 1.0
    validation_split:
      description: Ration of data used for validation
      default: 1.0
    gamma1:
      description: Smooth gamma1
      default: 4.0
    gamma2:
      description: Smooth gamma2
      default: 5.0
    gamma3:
      description: Smooth gamma3
      default: 10.0

- config: train-predict-flags
  description: Flags used by both train and predict
  flags:
    df_dim:
      description: DF dimension
      default: 96
    gf_dim:
      description: GF dimension
      default: 48
    z_dim:
      description: X dimension
      default: 100
    r_num:
      description: R
      default: 3

# -------------------------------------------------------------------
# AttnGAN
# -------------------------------------------------------------------

- model: attngan
  description: Fine-Grained Text to Image Generation with Attentional
               Generative Adversarial Networks

  # -----------------------------------------------------------------
  # AttnGAN resources
  # -----------------------------------------------------------------

  resources:
    cfg:
      description:
        Path to project configuration files.

        The AttnGAN project relies on default configuraiton located in
        the cfg directory. Some config values can be overridden by
        command line arguments to the operation script.
      sources:
        - file: cfg

    data-photosynthesis:
      description: Path to data used for training and test.
      sources:
        - url: https://github.com/gryBox/pytig-data/raw/master/photosynthesis_raw/photosynthesis.zip
          sha256: dffe12c931570eed15436181908bf998e9f2068554fd6cd584f444dc1785caa7

    pretrained-model:
      description:
        Models (pth files) generated by the pretrain operation.

        Selects the latest image and text encoders (determined by
        highest epoch value in file name) and names the files
        'image_encoder.pth' and 'text_encoder.pth' respectively.
      path: nets
      sources:
        - operation: pretrain
          select-max:
            - '.+/Model/image_encoder([0-9]+)\.pth'
            - '.+/Model/text_encoder([0-9]+)\.pth'
          rename:
            pattern: '[0-9]+'
            repl: ''

    trained-model:
      description:
        Models (pth files) generated by the train operation.

        Selects the latest netG model (determined by highest epoch
        value in file name) and names the file 'netG.pth'.
      path: nets
      sources:
        - operation: train
          select-max:
            - '.+/Model/netG_epoch_([0-9]+).pth'
          rename:
            pattern: _epoch_[0-9]+
            repl: ''

  operations:

    # ---------------------------------------------------------------
    # AttnGAN pretrain
    # ---------------------------------------------------------------

    pretrain:
      description: Pretrain the DAMSM model
      main: pretrain_DAMSM
             --data_dir ${dataset}
             --cfg cfg/DAMSM/${dataset}.yml
             --output_dir output
      requires:
        - cfg
        - data-${dataset}
      flags-import: no
      flags:
        $include:
          - common-flags
          - dataset-flags
          - pretrain-train-flags
        delete_captions_pickle:
          description: Force re-create of captions pickle
          arg-switch: yes
          default: yes
        encoder_lr:
          description: Encoder learning rate
          default: 0.0002
        rnn_grad_clip:
          description: RNN gradient clip
          default: 0.25 #197
      output-scalars:
        step: 'end epoch +([0-9]+)'
        s_loss: 'valid loss +([0-9\.]+)'
        w_loss: 'valid loss +[0-9\.]+ +([0-9\.]+)'
      objective: s_loss

    # ---------------------------------------------------------------
    # AttnGAN pretrain
    # ---------------------------------------------------------------

    train:
      description: Train the DAMSM model
      main: main
             --cfg cfg/photosynthesis_attn2.yml
             --data_dir photosynthesis
             --net_e nets/text_encoder.pth
             --output_dir output
      requires:
        - cfg
        - data-${dataset}
        - pretrained-model
      flags-import: no
      flags:
        $include:
          - common-flags
          - dataset-flags
          - pretrain-train-flags
          - train-predict-flags
        discriminator_lr:
          description: Discriminator learning rate
          default: 0.0002
        generator_lr:
          description: Generator learning rate
          default: 0.0002
        lambda:
          description: Lambda
          default: 50
      output-scalars:
        step: 'Step: ([0-9]+)'
        errD0: 'errD0: (\S+)'
        errD1: 'errD1: (\S+)'
        errD2: 'errD2: (\S+)'
        g_loss0: 'g_loss0: (\S+)'
        g_loss1: 'g_loss1: (\S+)'
        g_loss2: 'g_loss2: (\S+)'
        w_loss: 'w_loss: (\S+)'
        s_loss: 's_loss: (\S+)'
        kl_loss: 'kl_loss: (\S+)'
      objective: w_loss

    # ---------------------------------------------------------------
    # AttnGAN pretrain
    # ---------------------------------------------------------------

    predict:
      description: Predict on trained model
      main: main
             --predict
             --cfg cfg/eval_photosynthesis.yml
             --data_dir photosynthesis
             --net_e nets/text_encoder.pth
             --net_g nets/netG.pth
             --output_dir output
      requires:
        - cfg
        - data-${dataset}
        - pretrained-model
        - trained-model
      flags-import: no
      flags:
        $include:
          - common-flags
          - dataset-flags
          - train-predict-flags
        all_captions:
          description: Generate images for all captions
          default: no
          arg-switch: yes
          arg-name: b_validation

    # ---------------------------------------------------------------
    # AttnGAN workflow
    # ---------------------------------------------------------------

    all:
      description: Run the pipeline end-to-end
      flags:
        epochs: null
        pretrain_batch_size: null
        train_batch_size: null
      steps:
        - run: pretrain
               epochs=${epochs}
               batch_size=${pretrain_batch_size}
        - run: train
               epochs=${epochs}
               batch_size=${train_batch_size}
        - run: predict

    check:
      description: Quick check to verify pipeline
      steps:
        - run: all epochs=1
